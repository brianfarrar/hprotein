{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/farrar/py3.6.5/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import cv2\n",
    "from tensorflow.python.lib.io import file_io\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, load_model, Model\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense, Input, Conv2D, MaxPooling2D, BatchNormalization, Concatenate, ReLU, LeakyReLU\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "TRAIN_PATH = '../stage1_train'\n",
    "TEST_PATH = '../stage1_test'\n",
    "LABEL_PATH = '../stage1_labels/train.csv'\n",
    "OUTPUT_PATH = '../stage1_submit'\n",
    "COLORS = ['red','green', 'blue', 'yellow']\n",
    "IMAGE_SIZE = 512\n",
    "CROP_SIZE = 256\n",
    "BATCH_SIZE = 2\n",
    "SHAPE = (CROP_SIZE, CROP_SIZE, 4)\n",
    "THRESHOLD = 0.05\n",
    "SEED = 42\n",
    "\n",
    "\n",
    "name_label_dict = {\n",
    "0:  'Nucleoplasm',\n",
    "1:  'Nuclear membrane',\n",
    "2:  'Nucleoli',   \n",
    "3:  'Nucleoli fibrillar center',\n",
    "4:  'Nuclear speckles',\n",
    "5:  'Nuclear bodies',\n",
    "6:  'Endoplasmic reticulum',   \n",
    "7:  'Golgi apparatus',\n",
    "8:  'Peroxisomes',\n",
    "9:  'Endosomes',\n",
    "10:  'Lysosomes',\n",
    "11:  'Intermediate filaments',\n",
    "12:  'Actin filaments',\n",
    "13:  'Focal adhesion sites',   \n",
    "14:  'Microtubules',\n",
    "15:  'Microtubule ends',  \n",
    "16:  'Cytokinetic bridge',   \n",
    "17:  'Mitotic spindle',\n",
    "18:  'Microtubule organizing center',  \n",
    "19:  'Centrosome',\n",
    "20:  'Lipid droplets',\n",
    "21:  'Plasma membrane',   \n",
    "22:  'Cell junctions', \n",
    "23:  'Mitochondria',\n",
    "24:  'Aggresome',\n",
    "25:  'Cytosol',\n",
    "26:  'Cytoplasmic bodies',   \n",
    "27:  'Rods & rings' }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fffe0ffe-bbc0-11e8-b2bb-ac1f6b6435d0', '000c99ba-bba4-11e8-b2b9-ac1f6b6435d0', '001838f8-bbca-11e8-b2bc-ac1f6b6435d0', 'fc84a97c-bbad-11e8-b2ba-ac1f6b6435d0', '0020af02-bbba-11e8-b2ba-ac1f6b6435d0', '002daad6-bbc9-11e8-b2bc-ac1f6b6435d0', '001bcdd2-bbb2-11e8-b2ba-ac1f6b6435d0', 'ffeae6f0-bbc9-11e8-b2bc-ac1f6b6435d0', 'fea6e496-bbbb-11e8-b2ba-ac1f6b6435d0', 'fb4c1fac-bbaa-11e8-b2ba-ac1f6b6435d0']\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------\n",
    "# get a list of unique specimen ids\n",
    "# -----------------------------------------\n",
    "def get_specimen_ids(path):\n",
    "\n",
    "    # get a list of all the images\n",
    "    file_list = file_io.list_directory(path)\n",
    "    \n",
    "    # truncate the file names to make a specimen id\n",
    "    specimen_ids = [f[:36] for f in file_list]\n",
    "    \n",
    "    # eliminate duplicates\n",
    "    specimen_ids = list(set(specimen_ids))\n",
    "    \n",
    "    return specimen_ids\n",
    "\n",
    "# unit test\n",
    "specimen_list = get_specimen_ids(TRAIN_PATH)\n",
    "print(specimen_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../stage1_train/000c99ba-bba4-11e8-b2b9-ac1f6b6435d0_red.png\n"
     ]
    }
   ],
   "source": [
    "def get_image_fname(path, specimen_id, color, lo_res=True):\n",
    "\n",
    "    # construct filename\n",
    "    if lo_res:\n",
    "        fname = path + '/' + specimen_id + '_' + color + '.png'\n",
    "    else:\n",
    "        fname = path + '/' + specimen_id + '_' + color + '.tif'\n",
    "        \n",
    "    return fname\n",
    "\n",
    "# unit test\n",
    "s = '000c99ba-bba4-11e8-b2b9-ac1f6b6435d0'\n",
    "f = get_image_fname(TRAIN_PATH, s, 'red')\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00070df0-bbc3-11e8-b2bc-ac1f6b6435d0</td>\n",
       "      <td>16 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000a6c98-bb9b-11e8-b2b9-ac1f6b6435d0</td>\n",
       "      <td>7 1 2 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000a9596-bbc4-11e8-b2bc-ac1f6b6435d0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000c99ba-bba4-11e8-b2b9-ac1f6b6435d0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001838f8-bbca-11e8-b2bc-ac1f6b6435d0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>001bcdd2-bbb2-11e8-b2ba-ac1f6b6435d0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0020af02-bbba-11e8-b2ba-ac1f6b6435d0</td>\n",
       "      <td>25 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>002679c2-bbb6-11e8-b2ba-ac1f6b6435d0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>00285ce4-bba0-11e8-b2b9-ac1f6b6435d0</td>\n",
       "      <td>2 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>002daad6-bbc9-11e8-b2bc-ac1f6b6435d0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Id   Target\n",
       "0  00070df0-bbc3-11e8-b2bc-ac1f6b6435d0     16 0\n",
       "1  000a6c98-bb9b-11e8-b2b9-ac1f6b6435d0  7 1 2 0\n",
       "2  000a9596-bbc4-11e8-b2bc-ac1f6b6435d0        5\n",
       "3  000c99ba-bba4-11e8-b2b9-ac1f6b6435d0        1\n",
       "4  001838f8-bbca-11e8-b2bc-ac1f6b6435d0       18\n",
       "5  001bcdd2-bbb2-11e8-b2ba-ac1f6b6435d0        0\n",
       "6  0020af02-bbba-11e8-b2ba-ac1f6b6435d0     25 2\n",
       "7  002679c2-bbb6-11e8-b2ba-ac1f6b6435d0        0\n",
       "8  00285ce4-bba0-11e8-b2b9-ac1f6b6435d0      2 0\n",
       "9  002daad6-bbc9-11e8-b2bc-ac1f6b6435d0        7"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels = pd.read_csv(LABEL_PATH)\n",
    "train_labels.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    [7, 1, 2, 0]\n",
      "Name: Target, dtype: object\n"
     ]
    }
   ],
   "source": [
    "selection_list = ['000a6c98-bb9b-11e8-b2b9-ac1f6b6435d0', s, '001838f8-bbca-11e8-b2bc-ac1f6b6435d0']\n",
    "subset = train_labels.loc[train_labels['Id'].isin(selection_list)]\n",
    "subset.head()\n",
    "split_labels = (subset.loc[subset['Id'] == '000a6c98-bb9b-11e8-b2b9-ac1f6b6435d0'])['Target'].str.split(' ')\n",
    "print (split_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------\n",
    "# Keras style run time data generator\n",
    "# ---------------------------------------\n",
    "class HproteinDataGenerator(keras.utils.Sequence):\n",
    "    \n",
    "    # ---------------------------------------------\n",
    "    # Required function to initialize the class\n",
    "    # ---------------------------------------------\n",
    "    def __init__(self, \n",
    "                 path,\n",
    "                 specimen_ids, \n",
    "                 labels, \n",
    "                 batch_size=BATCH_SIZE,\n",
    "                 image_size=IMAGE_SIZE,\n",
    "                 crop_size=CROP_SIZE,\n",
    "                 shape=SHAPE, \n",
    "                 shuffle=True, \n",
    "                 use_cache=False, \n",
    "                 augment=False):\n",
    "       \n",
    "        self.path = path                       # path where data generator will find data\n",
    "        self.specimen_ids = specimen_ids       # list of features\n",
    "        self.labels = labels                   # list of labels\n",
    "        self.batch_size = batch_size           # batch size\n",
    "        self.image_size = image_size\n",
    "        self.crop_size = crop_size             # size to crop images to\n",
    "        self.last_batch_padding = 0            # amount to pad the last batch to make it complete\n",
    "        self.shape = shape                     # shape of features\n",
    "        self.shuffle = shuffle                 # boolean for shuffle\n",
    "        self.use_cache = use_cache             # boolean for use of cache\n",
    "        self.augment = augment                 # boolean for image augmentation\n",
    "        \n",
    "    # -------------------------------------------------------\n",
    "    # Required function to determine the number of batches\n",
    "    # -------------------------------------------------------\n",
    "    def __len__(self):\n",
    "        \n",
    "        # get the number of examples to generate\n",
    "        example_count = len(self.specimen_ids)\n",
    "        \n",
    "        # calculate the number of batches\n",
    "        batch_count = int(np.ceil(example_count / float(self.batch_size)))\n",
    "        \n",
    "        # get the size of the last batch\n",
    "        last_batch_size = example_count - ((batch_count - 1) * self.batch_size)\n",
    "        \n",
    "        # set the amount to pad the last batch\n",
    "        self.last_batch_padding = self.batch_size - last_batch_size\n",
    "        \n",
    "        return batch_count\n",
    "    \n",
    "    # -------------------------------------------------------\n",
    "    # Required function to get a batch\n",
    "    # -------------------------------------------------------\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        # get the list of specimen ids for this batch\n",
    "        specimen_ids = self.specimen_ids[self.batch_size*index:self.batch_size*(index + 1)]\n",
    "                \n",
    "        # create a zeroed out numpy array to load the batch into\n",
    "        feature_batch = np.zeros((len(specimen_ids), self.shape[0], self.shape[1], self.shape[2]))\n",
    "        \n",
    "        # load a batch of labels\n",
    "        label_batch = self.labels[self.batch_size*index:self.batch_size*(index + 1)]\n",
    "        \n",
    "        # load the batch with images and crop\n",
    "        for i, specimen_id in enumerate(specimen_ids):\n",
    "            feature_batch[i] = self.get_stacked_image(specimen_id)\n",
    "            \n",
    "        # augment images if desired\n",
    "        if self.augment:\n",
    "            print(\"Error: Image augmentation not implemented!\")\n",
    "            \n",
    "        return feature_batch, label_batch\n",
    "            \n",
    "            \n",
    "    # -----------------------------------------\n",
    "    # get a single image\n",
    "    # -----------------------------------------\n",
    "    def get_single_image(self, specimen_id, color, lo_res=True):\n",
    "\n",
    "        # get image file name\n",
    "        fname = get_image_fname(self.path, specimen_id, color, lo_res)\n",
    "        \n",
    "        # read image as a 1-channel image\n",
    "        image = cv2.imread(fname, cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        return image\n",
    "    \n",
    "            \n",
    "    # -----------------------------------------\n",
    "    # get a stacked (4-channel) image\n",
    "    # -----------------------------------------\n",
    "    def get_stacked_image(self, specimen_id, lo_res=True):\n",
    "\n",
    "        # create a numpy array to place the 1-channel images into\n",
    "        image = np.zeros((self.image_size, self.image_size, 4), dtype=np.uint8)\n",
    "\n",
    "        for n, color in enumerate(COLORS):\n",
    "\n",
    "            # get a single image\n",
    "            i = self.get_single_image(specimen_id, color, lo_res)\n",
    "\n",
    "            # store it a channel\n",
    "            image[:, :, n] = i\n",
    "            \n",
    "        crop = self.random_crop(image, crop_size=self.crop_size)\n",
    "\n",
    "        return crop\n",
    "\n",
    "    \n",
    "    # --------------------------------------------------\n",
    "    # crops an image to crop_size from a random origin\n",
    "    # --------------------------------------------------\n",
    "    def random_crop(self, image, crop_size=256, original_size=512):\n",
    "    \n",
    "        # get a pair of random coordinates that will provide for an image of crop_size\n",
    "        x_origin = random.randint(0, original_size - crop_size)\n",
    "        y_origin = random.randint(0, original_size - crop_size)\n",
    "        \n",
    "        print('before -> {}'.format(image.shape))\n",
    "        crop = image[x_origin : x_origin + crop_size, y_origin : y_origin + crop_size, :]\n",
    "        print('after  -> {}'.format(crop.shape))\n",
    "        return crop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specimen Id: fffe0ffe-bbc0-11e8-b2bb-ac1f6b6435d0 : Labels: [1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Specimen Id: 000c99ba-bba4-11e8-b2b9-ac1f6b6435d0 : Labels: [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Specimen Id: 001838f8-bbca-11e8-b2bc-ac1f6b6435d0 : Labels: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "Specimen Id: fc84a97c-bbad-11e8-b2ba-ac1f6b6435d0 : Labels: [1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Specimen Id: 0020af02-bbba-11e8-b2ba-ac1f6b6435d0 : Labels: [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      "Specimen Id: 002daad6-bbc9-11e8-b2bc-ac1f6b6435d0 : Labels: [0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Specimen Id: 001bcdd2-bbb2-11e8-b2ba-ac1f6b6435d0 : Labels: [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Specimen Id: ffeae6f0-bbc9-11e8-b2bc-ac1f6b6435d0 : Labels: [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      "Specimen Id: fea6e496-bbbb-11e8-b2ba-ac1f6b6435d0 : Labels: [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Specimen Id: fb4c1fac-bbaa-11e8-b2ba-ac1f6b6435d0 : Labels: [1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------------------\n",
    "# get the available specimen ids and corresponding labels\n",
    "# -----------------------------------------------------------\n",
    "def get_train_data(train_path, label_path):\n",
    "    \n",
    "    # get the list of specimen ids\n",
    "    specimen_ids = get_specimen_ids(train_path)\n",
    "    \n",
    "    # get the labels for all specimen_ids\n",
    "    label_data = pd.read_csv(label_path)\n",
    "    \n",
    "    # get the subset of labels that match the specimen images that are on TRAIN_PATH\n",
    "    labels_subset = label_data.loc[label_data['Id'].isin(specimen_ids)]\n",
    "    \n",
    "    #\n",
    "    # convert labels to trainer format\n",
    "    #\n",
    "    \n",
    "    # set up the list that will contain the list of encoded labels for each specimen id\n",
    "    labels = []\n",
    "    \n",
    "    # loop through each specimen_id\n",
    "    for specimen_id in specimen_ids:\n",
    "        \n",
    "        # split the space separated multi-label into a list of individual labels\n",
    "        split_labels = (labels_subset.loc[labels_subset['Id'] == specimen_id])['Target'].str.split(' ')\n",
    "\n",
    "        # set up a numpy array to receive the encoded label\n",
    "        l = np.zeros(28, dtype=np.uint8)\n",
    "\n",
    "        # turn on the positive columns in the labels array\n",
    "        for label in split_labels:\n",
    "            l[np.uint8(label)] = 1\n",
    "        \n",
    "        labels.append(l)\n",
    "        \n",
    "    return np.array(specimen_ids), np.array(labels)\n",
    "\n",
    "# unit test \n",
    "specimen_ids, labels = get_train_data(TRAIN_PATH, LABEL_PATH)\n",
    "for sid, l in zip(specimen_ids, labels):\n",
    "    print('Specimen Id: {} : Labels: {}'.format(sid, l))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specimen Id: 0031820a-baca-11e8-b2b8-ac1f6b6435d0 : Labels: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Specimen Id: 003170fa-bacd-11e8-b2b8-ac1f6b6435d0 : Labels: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Specimen Id: 0008baca-bad7-11e8-b2b9-ac1f6b6435d0 : Labels: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Specimen Id: 00d2a4f8-bad6-11e8-b2b9-ac1f6b6435d0 : Labels: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Specimen Id: 000cce7e-bad4-11e8-b2b8-ac1f6b6435d0 : Labels: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Specimen Id: 00cfafb0-bacb-11e8-b2b8-ac1f6b6435d0 : Labels: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Specimen Id: 0006faa6-bac7-11e8-b2b7-ac1f6b6435d0 : Labels: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------------------\n",
    "# get the specimen ids to predict\n",
    "# -----------------------------------------------------------\n",
    "def get_predict_data(test_path, output_path):\n",
    "    \n",
    "    # get the list of specimen ids for which there are images\n",
    "    specimen_ids = get_specimen_ids(test_path)\n",
    "    \n",
    "    # get the list of submission specimen ids required\n",
    "    submit_data = pd.read_csv(output_path + '/sample_submission.csv')\n",
    "    \n",
    "    # get the subset of labels that match the specimen images that are on TEST_PATH\n",
    "    submit_subset = submit_data.loc[submit_data['Id'].isin(specimen_ids)]\n",
    "    \n",
    "    # set up the list that will contain the list of encoded labels for each specimen id\n",
    "    predicted_labels = np.zeros((len(specimen_ids), 28), dtype=np.uint8)\n",
    "    \n",
    "    return np.array(specimen_ids), predicted_labels\n",
    "\n",
    "# unit test \n",
    "specimen_ids, labels = get_predict_data(TEST_PATH, OUTPUT_PATH)\n",
    "for sid, l in zip(specimen_ids, labels):\n",
    "    print('Specimen Id: {} : Labels: {}'.format(sid, l))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9473683\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------\n",
    "# calculate the f1 statistic\n",
    "# --------------------------------\n",
    "def f1(y_true, y_pred):\n",
    "    \n",
    "    #y_pred = K.round(y_pred)\n",
    "    y_pred = K.cast(K.greater(K.clip(y_pred, 0, 1), THRESHOLD), K.floatx())\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    \n",
    "    return K.mean(f1)\n",
    "\n",
    "# unit test\n",
    "y_true = K.variable(np.ones(10, np.uint8))\n",
    "y_pred = np.ones(10, np.uint8)\n",
    "y_pred[0] = 0\n",
    "y_pred = K.variable(y_pred)\n",
    "\n",
    "ftest = f1(y_true, y_pred)\n",
    "#ftest = tf.constant(5)\n",
    "\n",
    "init_op = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init_op)\n",
    "print (sess.run(ftest))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.052631676\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------\n",
    "# calculate the f1 loss\n",
    "# --------------------------------\n",
    "\n",
    "def f1_loss(y_true, y_pred):\n",
    "\n",
    "    f = f1(y_true, y_pred)\n",
    "    \n",
    "    return 1 - K.mean(f)\n",
    "\n",
    "# unit test\n",
    "y_true = K.variable(np.ones(10, np.uint8))\n",
    "y_pred = np.ones(10, np.uint8)\n",
    "y_pred[0] = 0\n",
    "y_pred = K.variable(y_pred)\n",
    "\n",
    "ftest = f1_loss(y_true, y_pred)\n",
    "#ftest = tf.constant(5)\n",
    "\n",
    "init_op = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init_op)\n",
    "print (sess.run(ftest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 256, 256, 4)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 256, 256, 4)  16          input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 254, 254, 8)  296         batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_1 (ReLU)                  (None, 254, 254, 8)  0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 254, 254, 8)  32          re_lu_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 252, 252, 8)  584         batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_2 (ReLU)                  (None, 252, 252, 8)  0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 252, 252, 8)  32          re_lu_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 250, 250, 16) 1168        batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_3 (ReLU)                  (None, 250, 250, 16) 0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 250, 250, 16) 64          re_lu_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 125, 125, 16) 0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 125, 125, 16) 0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 125, 125, 16) 2320        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 125, 125, 16) 6416        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 125, 125, 16) 12560       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 125, 125, 16) 272         dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_4 (ReLU)                  (None, 125, 125, 16) 0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_5 (ReLU)                  (None, 125, 125, 16) 0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_6 (ReLU)                  (None, 125, 125, 16) 0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_7 (ReLU)                  (None, 125, 125, 16) 0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 125, 125, 64) 0           re_lu_4[0][0]                    \n",
      "                                                                 re_lu_5[0][0]                    \n",
      "                                                                 re_lu_6[0][0]                    \n",
      "                                                                 re_lu_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 125, 125, 64) 256         concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 62, 62, 64)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 62, 62, 64)   0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 60, 60, 32)   18464       dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_8 (ReLU)                  (None, 60, 60, 32)   0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 60, 60, 32)   128         re_lu_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 30, 30, 32)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 30, 30, 32)   0           max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 28, 28, 64)   18496       dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_9 (ReLU)                  (None, 28, 28, 64)   0           conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 28, 28, 64)   256         re_lu_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 14, 14, 64)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 14, 14, 64)   0           max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 12, 12, 128)  73856       dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_10 (ReLU)                 (None, 12, 12, 128)  0           conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 12, 12, 128)  512         re_lu_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 6, 6, 128)    0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 6, 6, 128)    0           max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 4608)         0           dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 4608)         0           flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 28)           129052      dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_11 (ReLU)                 (None, 28)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 28)           112         re_lu_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 28)           0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 28)           812         dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 28)           0           dense_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 265,704\n",
      "Trainable params: 265,000\n",
      "Non-trainable params: 704\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------\n",
    "# create the model\n",
    "# ------------------------------\n",
    "def create_model(input_shape):\n",
    "\n",
    "    dropRate = 0.25\n",
    "    \n",
    "    init = Input(input_shape)\n",
    "    x = BatchNormalization(axis=-1)(init)\n",
    "    x = Conv2D(8, (3, 3))(x)\n",
    "    x = ReLU()(x)\n",
    "    x = BatchNormalization(axis=-1)(x)\n",
    "    x = Conv2D(8, (3, 3))(x)\n",
    "    x = ReLU()(x)\n",
    "    x = BatchNormalization(axis=-1)(x)\n",
    "    x = Conv2D(16, (3, 3))(x)\n",
    "    x = ReLU()(x)\n",
    "    x = BatchNormalization(axis=-1)(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Dropout(dropRate)(x)\n",
    "    c1 = Conv2D(16, (3, 3), padding='same')(x)\n",
    "    c1 = ReLU()(c1)\n",
    "    c2 = Conv2D(16, (5, 5), padding='same')(x)\n",
    "    c2 = ReLU()(c2)\n",
    "    c3 = Conv2D(16, (7, 7), padding='same')(x)\n",
    "    c3 = ReLU()(c3)\n",
    "    c4 = Conv2D(16, (1, 1), padding='same')(x)\n",
    "    c4 = ReLU()(c4)\n",
    "    x = Concatenate()([c1, c2, c3, c4])\n",
    "    x = BatchNormalization(axis=-1)(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Dropout(dropRate)(x)\n",
    "    x = Conv2D(32, (3, 3))(x)\n",
    "    x = ReLU()(x)\n",
    "    x = BatchNormalization(axis=-1)(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Dropout(dropRate)(x)\n",
    "    x = Conv2D(64, (3, 3))(x)\n",
    "    x = ReLU()(x)\n",
    "    x = BatchNormalization(axis=-1)(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Dropout(dropRate)(x)\n",
    "    x = Conv2D(128, (3, 3))(x)\n",
    "    x = ReLU()(x)\n",
    "    x = BatchNormalization(axis=-1)(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Dropout(dropRate)(x)\n",
    "    #x = Conv2D(256, (1, 1), activation='relu')(x)\n",
    "    #x = BatchNormalization(axis=-1)(x)\n",
    "    #x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    #x = Dropout(0.25)(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(28)(x)\n",
    "    x = ReLU()(x)\n",
    "    x = BatchNormalization(axis=-1)(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    x = Dense(28)(x)\n",
    "    x = Activation('sigmoid')(x)\n",
    "    \n",
    "    model = Model(init, x)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# unit test\n",
    "model = create_model(SHAPE)\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer=Adam(1e-03),\n",
    "    metrics=['acc',f1])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7,)\n",
      "(3,)\n",
      "4\n",
      "2\n",
      "['fea6e496-bbbb-11e8-b2ba-ac1f6b6435d0'\n",
      " '000c99ba-bba4-11e8-b2b9-ac1f6b6435d0'\n",
      " '002daad6-bbc9-11e8-b2bc-ac1f6b6435d0'] [[0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# get data\n",
    "def get_data(test_size=0.1):\n",
    "    \n",
    "    specimen_ids, labels = get_train_data(TRAIN_PATH, LABEL_PATH)\n",
    "    train_set_sids, val_set_sids, train_set_lbls, val_set_lbls = train_test_split(specimen_ids, labels, test_size=test_size, random_state=SEED)\n",
    "    \n",
    "    return train_set_sids, val_set_sids, train_set_lbls, val_set_lbls\n",
    "\n",
    "# unit test\n",
    "train_set_sids, val_set_sids, train_set_lbls, val_set_lbls = get_data(test_size=0.3)\n",
    "print (train_set_sids.shape)\n",
    "print (val_set_sids.shape)\n",
    "\n",
    "# create data generators\n",
    "tg = HproteinDataGenerator(TRAIN_PATH, train_set_sids, train_set_lbls)\n",
    "vg = HproteinDataGenerator(TRAIN_PATH, val_set_sids, val_set_lbls)\n",
    "print(len(tg))\n",
    "print(len(vg))\n",
    "print (val_set_sids, val_set_lbls)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint('./base.model', monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='min', period=1)\n",
    "reduceLROnPlato = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1, mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "3/4 [=====================>........] - ETA: 1s - loss: 0.7448 - acc: 0.6667 - f1: 0.0754before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "4/4 [==============================] - 8s 2s/step - loss: 0.7626 - acc: 0.5980 - f1: 0.0786 - val_loss: 1.5830 - val_acc: 0.6071 - val_f1: 0.0387\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.58299, saving model to ./base.model\n",
      "Epoch 2/5\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.7406 - acc: 0.6012 - f1: 0.0714before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.7447 - acc: 0.5740 - f1: 0.0786 - val_loss: 0.6380 - val_acc: 0.6458 - val_f1: 0.0437\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.58299 to 0.63799, saving model to ./base.model\n",
      "Epoch 3/5\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.7461 - acc: 0.4762 - f1: 0.0913before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.7320 - acc: 0.5878 - f1: 0.0786 - val_loss: 0.6561 - val_acc: 0.6101 - val_f1: 0.0437\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.63799\n",
      "Epoch 4/5\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.7385 - acc: 0.6726 - f1: 0.0714before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.7393 - acc: 0.6383 - f1: 0.0786 - val_loss: 0.6914 - val_acc: 0.6369 - val_f1: 0.0437\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.63799\n",
      "Epoch 5/5\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.7200 - acc: 0.6905 - f1: 0.0714before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.7197 - acc: 0.6372 - f1: 0.0786 - val_loss: 0.7470 - val_acc: 0.6399 - val_f1: 0.0407\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.63799\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "\n",
    "use_multiprocessing = False # DO NOT COMBINE MULTIPROCESSING WITH CACHE! \n",
    "workers = 1 # DO NOT COMBINE MULTIPROCESSING WITH CACHE! \n",
    "\n",
    "hist = model.fit_generator(\n",
    "    tg,\n",
    "    steps_per_epoch=len(tg),\n",
    "    validation_data=vg,\n",
    "    validation_steps=8,\n",
    "    epochs=epochs,\n",
    "    use_multiprocessing=use_multiprocessing,\n",
    "    workers=workers,\n",
    "    verbose=1,\n",
    "    callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x131fdbba8>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(15,5))\n",
    "ax[0].set_title('loss')\n",
    "ax[0].plot(hist.epoch, hist.history[\"loss\"], label=\"Train loss\")\n",
    "ax[0].plot(hist.epoch, hist.history[\"val_loss\"], label=\"Validation loss\")\n",
    "ax[1].set_title('acc')\n",
    "ax[1].plot(hist.epoch, hist.history[\"f1\"], label=\"Train F1\")\n",
    "ax[1].plot(hist.epoch, hist.history[\"val_f1\"], label=\"Validation F1\")\n",
    "ax[0].legend()\n",
    "ax[1].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = load_model('./base.model', custom_objects={'f1': f1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "(3, 28)\n",
      "(3, 28)\n",
      "[[0.25240365 0.55149066 0.13841696 0.42964354 0.42269263 0.38355693\n",
      "  0.42369771 0.23436081 0.71587414 0.69582075 0.73850542 0.57660568\n",
      "  0.85191613 0.38432184 0.73817503 0.23672265 0.50334758 0.2530283\n",
      "  0.7095232  0.37436184 0.33581984 0.40107554 0.18683967 0.34871626\n",
      "  0.43545547 0.51464313 0.09347416 0.84290659]\n",
      " [0.23921522 0.87769157 0.38930225 0.65958738 0.71748734 0.31304604\n",
      "  0.81351763 0.47168934 0.46793547 0.6009683  0.43323007 0.12473943\n",
      "  0.80076122 0.22870333 0.62477964 0.35525015 0.53582162 0.40971136\n",
      "  0.52460194 0.2769497  0.25414637 0.78282976 0.4496924  0.02824184\n",
      "  0.35052133 0.79163474 0.10372406 0.81564993]\n",
      " [0.10307997 0.82615042 0.59705108 0.50977743 0.37806016 0.46277297\n",
      "  0.69885528 0.38594684 0.35026035 0.57017308 0.26372519 0.54506254\n",
      "  0.62027407 0.03525889 0.2761201  0.25585717 0.19295003 0.57194954\n",
      "  0.45032126 0.34763268 0.56787133 0.53143239 0.12034184 0.04506851\n",
      "  0.25609145 0.76129752 0.19951993 0.71677452]]\n"
     ]
    }
   ],
   "source": [
    "val_predictions = np.empty((0, 28))\n",
    "val_labels = np.empty((0, 28))\n",
    "for i in range(len(vg)):\n",
    "    image, label = vg[i]\n",
    "    scores = final_model.predict(image)\n",
    "    #print('scores -> {}'.format(scores))\n",
    "    #print('label  -> {}'.format(label))\n",
    "    val_predictions = np.append(val_predictions, scores, axis=0)\n",
    "    val_labels = np.append(val_labels, label, axis=0)\n",
    "print(val_predictions.shape)\n",
    "print(val_labels.shape)\n",
    "print(val_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/farrar/py3.6.5/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/Users/farrar/py3.6.5/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 28)\n",
      "[[0.  0.5 0.  ... 0.  0.  0. ]\n",
      " [0.  0.5 0.  ... 0.  0.  0. ]\n",
      " [0.  0.5 0.  ... 0.  0.  0. ]\n",
      " ...\n",
      " [0.  0.  0.  ... 0.  0.  0. ]\n",
      " [0.  0.  0.  ... 0.  0.  0. ]\n",
      " [0.  0.  0.  ... 0.  0.  0. ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "rng = np.arange(0, 1, 0.001)\n",
    "fscores = np.zeros((rng.shape[0], 28))\n",
    "for j,k in enumerate(rng):\n",
    "    for i in range(28):\n",
    "        p = np.array(val_predictions[:,i]>k, dtype=np.int8)\n",
    "        #print('p -> {}'.format(p))\n",
    "        #print('v -> {}'.format(val_predictions[:,i]))\n",
    "        #print('l -> {}'.format(val_labels[:,i]))\n",
    "        score = f1_score(val_labels[:,i], p, average='binary')\n",
    "        #print(score)\n",
    "        fscores[j,i] = score\n",
    "        \n",
    "        \n",
    "print (fscores.shape)\n",
    "print (fscores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual F1-scores for each class:\n",
      "[0.         1.         0.         0.         0.         0.\n",
      " 0.         0.66666667 0.         0.         0.         0.\n",
      " 1.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.        ]\n",
      "Macro F1-score CV = 0.09523809523809523\n"
     ]
    }
   ],
   "source": [
    "print('Individual F1-scores for each class:')\n",
    "print(np.max(fscores, axis=0))\n",
    "print('Macro F1-score CV =', np.mean(np.max(fscores, axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability threshold maximizing CV F1-score for each class:\n",
      "[0.    0.827 0.    0.    0.    0.    0.    0.235 0.    0.    0.    0.\n",
      " 0.801 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.   ]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(rng, fscores)\n",
    "p_threshold = np.empty(28)\n",
    "for i in range(28):\n",
    "    p_threshold[i] = rng[np.where(fscores[:,i] == np.max(fscores[:,i]))[0][0]]\n",
    "print('Probability threshold maximizing CV F1-score for each class:')\n",
    "print(p_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "1\n",
      "['0031820a-baca-11e8-b2b8-ac1f6b6435d0'\n",
      " '003170fa-bacd-11e8-b2b8-ac1f6b6435d0'\n",
      " '0008baca-bad7-11e8-b2b9-ac1f6b6435d0'\n",
      " '00d2a4f8-bad6-11e8-b2b9-ac1f6b6435d0'\n",
      " '000cce7e-bad4-11e8-b2b8-ac1f6b6435d0'\n",
      " '00cfafb0-bacb-11e8-b2b8-ac1f6b6435d0'\n",
      " '0006faa6-bac7-11e8-b2b7-ac1f6b6435d0'] [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "predict_set_sids, predict_set_lbls = get_predict_data(TEST_PATH, OUTPUT_PATH)\n",
    "pg = HproteinDataGenerator(TEST_PATH, predict_set_sids, predict_set_lbls)\n",
    "\n",
    "print(len(pg))\n",
    "print(pg.last_batch_padding)\n",
    "print (predict_set_sids, predict_set_lbls)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "blank rows shape (1, 256, 256, 4)\n",
      "Images Shape After: (2, 256, 256, 4)\n",
      "[[0.49203286 0.727247   0.44252595 0.56971371 0.43764538 0.25350571\n",
      "  0.44199121 0.29554486 0.80962384 0.28566882 0.40786505 0.33592352\n",
      "  0.58073068 0.2174053  0.27452123 0.48976725 0.64190465 0.26698059\n",
      "  0.45333162 0.19163099 0.58014166 0.74943238 0.36747578 0.27175003\n",
      "  0.13558222 0.65302014 0.19112986 0.84009117]\n",
      " [0.28555158 0.93474996 0.56902039 0.43386447 0.47201371 0.6327278\n",
      "  0.71014196 0.54668033 0.66552699 0.3940815  0.40079966 0.50843662\n",
      "  0.43487269 0.09682455 0.5326004  0.34296384 0.43719587 0.42371759\n",
      "  0.3921037  0.51509225 0.75620443 0.86453295 0.06199847 0.05415692\n",
      "  0.3802442  0.88346857 0.26185367 0.85442686]\n",
      " [0.1567664  0.54389179 0.47943696 0.69348258 0.38383099 0.18280791\n",
      "  0.6272701  0.13202773 0.16063292 0.84822744 0.09595508 0.3474918\n",
      "  0.52774727 0.03734343 0.34355712 0.42541116 0.19204804 0.35364965\n",
      "  0.38652566 0.38494512 0.4790093  0.53514493 0.15860066 0.01156059\n",
      "  0.20417459 0.94804788 0.18864129 0.84882736]\n",
      " [0.20010121 0.57110035 0.68387806 0.61731136 0.43854159 0.29643479\n",
      "  0.72365445 0.2059491  0.11965105 0.8292504  0.1034762  0.38895896\n",
      "  0.49722788 0.02466784 0.3626608  0.51718408 0.14197874 0.24314496\n",
      "  0.38018578 0.23936643 0.5207479  0.38899237 0.18004596 0.00932304\n",
      "  0.24388276 0.95553976 0.25644052 0.77181709]\n",
      " [0.55641156 0.80702341 0.60725611 0.71241641 0.52641022 0.38665375\n",
      "  0.54263735 0.42005691 0.73137808 0.19298626 0.43166375 0.30176294\n",
      "  0.50565183 0.11628249 0.43607441 0.40835789 0.48883739 0.38755828\n",
      "  0.39471248 0.28479311 0.60606134 0.7664305  0.26664767 0.16460045\n",
      "  0.16966809 0.78619027 0.1712587  0.83658385]\n",
      " [0.17968257 0.26794884 0.41765773 0.71118361 0.24641326 0.27928358\n",
      "  0.57881391 0.22570442 0.1619816  0.73642874 0.09231933 0.62868893\n",
      "  0.21502164 0.04562295 0.42328006 0.42949942 0.10450749 0.13150626\n",
      "  0.57130724 0.21704629 0.4371447  0.28552443 0.11624912 0.05511477\n",
      "  0.23833352 0.95811915 0.54889566 0.81332463]\n",
      " [0.43498865 0.81490558 0.74685496 0.45899525 0.33511841 0.655931\n",
      "  0.54699248 0.59490258 0.38481534 0.35275209 0.42431945 0.62065971\n",
      "  0.21420647 0.24277741 0.66239429 0.48641792 0.23077273 0.49682525\n",
      "  0.52242225 0.83393353 0.8288222  0.780496   0.21477561 0.18282299\n",
      "  0.45644212 0.71001107 0.41304812 0.67349708]\n",
      " [0.11095107 0.40987819 0.46633574 0.70469046 0.31750783 0.21528494\n",
      "  0.66503036 0.11018539 0.12614974 0.86691147 0.07284524 0.38603193\n",
      "  0.42733964 0.01922016 0.25139827 0.53183579 0.18393101 0.37073037\n",
      "  0.4358606  0.22887829 0.40400243 0.44022459 0.1362348  0.00837205\n",
      "  0.17830031 0.9658531  0.27817672 0.84029752]]\n"
     ]
    }
   ],
   "source": [
    "predictions = np.zeros((predict_set_sids.shape[0] + pg.last_batch_padding, 28))\n",
    "for i in range(len(pg)):\n",
    "    images, labels = pg[i]\n",
    "    if (images.shape[0] < pg.batch_size):\n",
    "        blank_rows = np.zeros((pg.last_batch_padding, pg.shape[0], pg.shape[1], pg.shape[2]))\n",
    "        print('blank rows shape {}'.format(blank_rows.shape))\n",
    "        images = np.append(images, blank_rows, axis=0)\n",
    "        print ('Images Shape After: {}'.format(images.shape))\n",
    "    score = final_model.predict(images)\n",
    "    predictions[i*BATCH_SIZE:i*BATCH_SIZE+images.shape[0]] = score\n",
    "    \n",
    "print (predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the list of submission specimen ids required\n",
    "submit_data = pd.read_csv(OUTPUT_PATH + '/sample_submission.csv')\n",
    "\n",
    "# get the subset of labels that match the specimen images that are on TEST_PATH\n",
    "submit_data = submit_data.loc[submit_data['Id'].isin(specimen_ids)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 28)\n"
     ]
    }
   ],
   "source": [
    "prediction_str = []\n",
    "print(predictions.shape)\n",
    "predictions = predictions[:predictions.shape[0] - pg.last_batch_padding, :]\n",
    "for i in range(predictions.shape[0]):\n",
    "    submit_str = ' '\n",
    "    for j in range(predictions.shape[1]):\n",
    "        if predictions[i,j] >= p_threshold[j]:\n",
    "            submit_str += str(j) + ' '\n",
    "            \n",
    "    prediction_str.append(submit_str)\n",
    "    \n",
    "submit_data['Predicted'] = np.array(prediction_str)\n",
    "\n",
    "submit_data.to_csv(OUTPUT_PATH + '/submit_3434.csv', index=False)\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndef random_crop(image, crop_size=256, original_size=512):\\n    \\n    # get a pair of random coordinates that will provide for an image of crop_size\\n    x_origin = random.randint(0, original_size - crop_size)\\n    y_origin = random.randint(0, original_size - crop_size)\\n    \\n    crop = image[x_origin : x_origin + crop_size, y_origin : y_origin + crop_size, :]\\n    \\n    return crop\\n\\n# unit test\\nimg, lbl = tg[0]\\nimage = img[i]\\ncrop = random_crop(image, crop_size=128, original_size=256)\\nprint('Shape before -> {}'.format(image.shape))\\nprint('Shape after  -> {}'.format(crop.shape))\\n\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def random_crop(image, crop_size=256, original_size=512):\n",
    "    \n",
    "    # get a pair of random coordinates that will provide for an image of crop_size\n",
    "    x_origin = random.randint(0, original_size - crop_size)\n",
    "    y_origin = random.randint(0, original_size - crop_size)\n",
    "    \n",
    "    crop = image[x_origin : x_origin + crop_size, y_origin : y_origin + crop_size, :]\n",
    "    \n",
    "    return crop\n",
    "\n",
    "# unit test\n",
    "img, lbl = tg[0]\n",
    "image = img[i]\n",
    "crop = random_crop(image, crop_size=128, original_size=256)\n",
    "print('Shape before -> {}'.format(image.shape))\n",
    "print('Shape after  -> {}'.format(crop.shape))\n",
    "'''    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
