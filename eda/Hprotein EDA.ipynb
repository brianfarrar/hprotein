{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/farrar/py3.6.5/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import cv2\n",
    "from tensorflow.python.lib.io import file_io\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, load_model, Model\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense, Input, Conv2D, MaxPooling2D, BatchNormalization, Concatenate, ReLU, LeakyReLU\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "TRAIN_PATH = '../stage1_train'\n",
    "TEST_PATH = '../stage1_test'\n",
    "LABEL_PATH = '../stage1_labels/train.csv'\n",
    "OUTPUT_PATH = '../stage1_submit'\n",
    "COLORS = ['red','green', 'blue', 'yellow']\n",
    "IMAGE_SIZE = 512\n",
    "CROP_SIZE = 256\n",
    "BATCH_SIZE = 2\n",
    "SHAPE = (CROP_SIZE, CROP_SIZE, 4)\n",
    "THRESHOLD = 0.05\n",
    "SEED = 42\n",
    "\n",
    "\n",
    "name_label_dict = {\n",
    "0:  'Nucleoplasm',\n",
    "1:  'Nuclear membrane',\n",
    "2:  'Nucleoli',   \n",
    "3:  'Nucleoli fibrillar center',\n",
    "4:  'Nuclear speckles',\n",
    "5:  'Nuclear bodies',\n",
    "6:  'Endoplasmic reticulum',   \n",
    "7:  'Golgi apparatus',\n",
    "8:  'Peroxisomes',\n",
    "9:  'Endosomes',\n",
    "10:  'Lysosomes',\n",
    "11:  'Intermediate filaments',\n",
    "12:  'Actin filaments',\n",
    "13:  'Focal adhesion sites',   \n",
    "14:  'Microtubules',\n",
    "15:  'Microtubule ends',  \n",
    "16:  'Cytokinetic bridge',   \n",
    "17:  'Mitotic spindle',\n",
    "18:  'Microtubule organizing center',  \n",
    "19:  'Centrosome',\n",
    "20:  'Lipid droplets',\n",
    "21:  'Plasma membrane',   \n",
    "22:  'Cell junctions', \n",
    "23:  'Mitochondria',\n",
    "24:  'Aggresome',\n",
    "25:  'Cytosol',\n",
    "26:  'Cytoplasmic bodies',   \n",
    "27:  'Rods & rings' }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['000c99ba-bba4-11e8-b2b9-ac1f6b6435d0', 'fc84a97c-bbad-11e8-b2ba-ac1f6b6435d0', 'ffeae6f0-bbc9-11e8-b2bc-ac1f6b6435d0', 'fb4c1fac-bbaa-11e8-b2ba-ac1f6b6435d0', '0020af02-bbba-11e8-b2ba-ac1f6b6435d0', '001838f8-bbca-11e8-b2bc-ac1f6b6435d0', 'fffe0ffe-bbc0-11e8-b2bb-ac1f6b6435d0', '002daad6-bbc9-11e8-b2bc-ac1f6b6435d0', '001bcdd2-bbb2-11e8-b2ba-ac1f6b6435d0', 'fea6e496-bbbb-11e8-b2ba-ac1f6b6435d0']\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------\n",
    "# get a list of unique specimen ids\n",
    "# -----------------------------------------\n",
    "def get_specimen_ids(path):\n",
    "\n",
    "    # get a list of all the images\n",
    "    file_list = file_io.list_directory(path)\n",
    "    \n",
    "    # truncate the file names to make a specimen id\n",
    "    specimen_ids = [f[:36] for f in file_list]\n",
    "    \n",
    "    # eliminate duplicates\n",
    "    specimen_ids = list(set(specimen_ids))\n",
    "    \n",
    "    return specimen_ids\n",
    "\n",
    "# unit test\n",
    "specimen_list = get_specimen_ids(TRAIN_PATH)\n",
    "print(specimen_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../stage1_train/000c99ba-bba4-11e8-b2b9-ac1f6b6435d0_red.png\n"
     ]
    }
   ],
   "source": [
    "def get_image_fname(path, specimen_id, color, lo_res=True):\n",
    "\n",
    "    # construct filename\n",
    "    if lo_res:\n",
    "        fname = path + '/' + specimen_id + '_' + color + '.png'\n",
    "    else:\n",
    "        fname = path + '/' + specimen_id + '_' + color + '.tif'\n",
    "        \n",
    "    return fname\n",
    "\n",
    "# unit test\n",
    "s = '000c99ba-bba4-11e8-b2b9-ac1f6b6435d0'\n",
    "f = get_image_fname(TRAIN_PATH, s, 'red')\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00070df0-bbc3-11e8-b2bc-ac1f6b6435d0</td>\n",
       "      <td>16 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000a6c98-bb9b-11e8-b2b9-ac1f6b6435d0</td>\n",
       "      <td>7 1 2 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000a9596-bbc4-11e8-b2bc-ac1f6b6435d0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000c99ba-bba4-11e8-b2b9-ac1f6b6435d0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001838f8-bbca-11e8-b2bc-ac1f6b6435d0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>001bcdd2-bbb2-11e8-b2ba-ac1f6b6435d0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0020af02-bbba-11e8-b2ba-ac1f6b6435d0</td>\n",
       "      <td>25 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>002679c2-bbb6-11e8-b2ba-ac1f6b6435d0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>00285ce4-bba0-11e8-b2b9-ac1f6b6435d0</td>\n",
       "      <td>2 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>002daad6-bbc9-11e8-b2bc-ac1f6b6435d0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Id   Target\n",
       "0  00070df0-bbc3-11e8-b2bc-ac1f6b6435d0     16 0\n",
       "1  000a6c98-bb9b-11e8-b2b9-ac1f6b6435d0  7 1 2 0\n",
       "2  000a9596-bbc4-11e8-b2bc-ac1f6b6435d0        5\n",
       "3  000c99ba-bba4-11e8-b2b9-ac1f6b6435d0        1\n",
       "4  001838f8-bbca-11e8-b2bc-ac1f6b6435d0       18\n",
       "5  001bcdd2-bbb2-11e8-b2ba-ac1f6b6435d0        0\n",
       "6  0020af02-bbba-11e8-b2ba-ac1f6b6435d0     25 2\n",
       "7  002679c2-bbb6-11e8-b2ba-ac1f6b6435d0        0\n",
       "8  00285ce4-bba0-11e8-b2b9-ac1f6b6435d0      2 0\n",
       "9  002daad6-bbc9-11e8-b2bc-ac1f6b6435d0        7"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels = pd.read_csv(LABEL_PATH)\n",
    "train_labels.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    [7, 1, 2, 0]\n",
      "Name: Target, dtype: object\n"
     ]
    }
   ],
   "source": [
    "selection_list = ['000a6c98-bb9b-11e8-b2b9-ac1f6b6435d0', s, '001838f8-bbca-11e8-b2bc-ac1f6b6435d0']\n",
    "subset = train_labels.loc[train_labels['Id'].isin(selection_list)]\n",
    "subset.head()\n",
    "split_labels = (subset.loc[subset['Id'] == '000a6c98-bb9b-11e8-b2b9-ac1f6b6435d0'])['Target'].str.split(' ')\n",
    "print (split_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------\n",
    "# Keras style run time data generator\n",
    "# ---------------------------------------\n",
    "class HproteinDataGenerator(keras.utils.Sequence):\n",
    "    \n",
    "    # ---------------------------------------------\n",
    "    # Required function to initialize the class\n",
    "    # ---------------------------------------------\n",
    "    def __init__(self, \n",
    "                 path,\n",
    "                 specimen_ids, \n",
    "                 labels, \n",
    "                 batch_size=BATCH_SIZE,\n",
    "                 image_size=IMAGE_SIZE,\n",
    "                 crop_size=CROP_SIZE,\n",
    "                 shape=SHAPE, \n",
    "                 shuffle=True, \n",
    "                 use_cache=False, \n",
    "                 augment=False):\n",
    "       \n",
    "        self.path = path                       # path where data generator will find data\n",
    "        self.specimen_ids = specimen_ids       # list of features\n",
    "        self.labels = labels                   # list of labels\n",
    "        self.batch_size = batch_size           # batch size\n",
    "        self.image_size = image_size\n",
    "        self.crop_size = crop_size             # size to crop images to\n",
    "        self.last_batch_padding = 0            # amount to pad the last batch to make it complete\n",
    "        self.shape = shape                     # shape of features\n",
    "        self.shuffle = shuffle                 # boolean for shuffle\n",
    "        self.use_cache = use_cache             # boolean for use of cache\n",
    "        self.augment = augment                 # boolean for image augmentation\n",
    "        \n",
    "    # -------------------------------------------------------\n",
    "    # Required function to determine the number of batches\n",
    "    # -------------------------------------------------------\n",
    "    def __len__(self):\n",
    "        \n",
    "        # get the number of examples to generate\n",
    "        example_count = len(self.specimen_ids)\n",
    "        \n",
    "        # calculate the number of batches\n",
    "        batch_count = int(np.ceil(example_count / float(self.batch_size)))\n",
    "        \n",
    "        # get the size of the last batch\n",
    "        last_batch_size = example_count - ((batch_count - 1) * self.batch_size)\n",
    "        \n",
    "        # set the amount to pad the last batch\n",
    "        self.last_batch_padding = self.batch_size - last_batch_size\n",
    "        \n",
    "        return batch_count\n",
    "    \n",
    "    # -------------------------------------------------------\n",
    "    # Required function to get a batch\n",
    "    # -------------------------------------------------------\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        # get the list of specimen ids for this batch\n",
    "        specimen_ids = self.specimen_ids[self.batch_size*index:self.batch_size*(index + 1)]\n",
    "                \n",
    "        # create a zeroed out numpy array to load the batch into\n",
    "        feature_batch = np.zeros((len(specimen_ids), self.shape[0], self.shape[1], self.shape[2]))\n",
    "        \n",
    "        # load a batch of labels\n",
    "        label_batch = self.labels[self.batch_size*index:self.batch_size*(index + 1)]\n",
    "        \n",
    "        # load the batch with images and crop\n",
    "        for i, specimen_id in enumerate(specimen_ids):\n",
    "            feature_batch[i] = self.get_stacked_image(specimen_id)\n",
    "            \n",
    "        # augment images if desired\n",
    "        if self.augment:\n",
    "            print(\"Error: Image augmentation not implemented!\")\n",
    "            \n",
    "        return feature_batch, label_batch\n",
    "            \n",
    "            \n",
    "    # -----------------------------------------\n",
    "    # get a single image\n",
    "    # -----------------------------------------\n",
    "    def get_single_image(self, specimen_id, color, lo_res=True):\n",
    "\n",
    "        # get image file name\n",
    "        fname = get_image_fname(self.path, specimen_id, color, lo_res)\n",
    "        \n",
    "        # read image as a 1-channel image\n",
    "        image = cv2.imread(fname, cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        return image\n",
    "    \n",
    "            \n",
    "    # -----------------------------------------\n",
    "    # get a stacked (4-channel) image\n",
    "    # -----------------------------------------\n",
    "    def get_stacked_image(self, specimen_id, lo_res=True):\n",
    "\n",
    "        # create a numpy array to place the 1-channel images into\n",
    "        image = np.zeros((self.image_size, self.image_size, 4), dtype=np.uint8)\n",
    "\n",
    "        for n, color in enumerate(COLORS):\n",
    "\n",
    "            # get a single image\n",
    "            i = self.get_single_image(specimen_id, color, lo_res)\n",
    "\n",
    "            # store it a channel\n",
    "            image[:, :, n] = i\n",
    "            \n",
    "        crop = self.random_crop(image, crop_size=self.crop_size)\n",
    "\n",
    "        return crop\n",
    "\n",
    "    \n",
    "    # --------------------------------------------------\n",
    "    # crops an image to crop_size from a random origin\n",
    "    # --------------------------------------------------\n",
    "    def random_crop(self, image, crop_size=256, original_size=512):\n",
    "    \n",
    "        # get a pair of random coordinates that will provide for an image of crop_size\n",
    "        x_origin = random.randint(0, original_size - crop_size)\n",
    "        y_origin = random.randint(0, original_size - crop_size)\n",
    "        \n",
    "        print('before -> {}'.format(image.shape))\n",
    "        crop = image[x_origin : x_origin + crop_size, y_origin : y_origin + crop_size, :]\n",
    "        print('after  -> {}'.format(crop.shape))\n",
    "        return crop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specimen Id: 000c99ba-bba4-11e8-b2b9-ac1f6b6435d0 : Labels: [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Specimen Id: fc84a97c-bbad-11e8-b2ba-ac1f6b6435d0 : Labels: [1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Specimen Id: ffeae6f0-bbc9-11e8-b2bc-ac1f6b6435d0 : Labels: [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      "Specimen Id: fb4c1fac-bbaa-11e8-b2ba-ac1f6b6435d0 : Labels: [1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Specimen Id: 0020af02-bbba-11e8-b2ba-ac1f6b6435d0 : Labels: [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      "Specimen Id: 001838f8-bbca-11e8-b2bc-ac1f6b6435d0 : Labels: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "Specimen Id: fffe0ffe-bbc0-11e8-b2bb-ac1f6b6435d0 : Labels: [1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Specimen Id: 002daad6-bbc9-11e8-b2bc-ac1f6b6435d0 : Labels: [0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Specimen Id: 001bcdd2-bbb2-11e8-b2ba-ac1f6b6435d0 : Labels: [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Specimen Id: fea6e496-bbbb-11e8-b2ba-ac1f6b6435d0 : Labels: [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------------------\n",
    "# get the available specimen ids and corresponding labels\n",
    "# -----------------------------------------------------------\n",
    "def get_train_data(train_path, label_path):\n",
    "    \n",
    "    # get the list of specimen ids\n",
    "    specimen_ids = get_specimen_ids(train_path)\n",
    "    \n",
    "    # get the labels for all specimen_ids\n",
    "    label_data = pd.read_csv(label_path)\n",
    "    \n",
    "    # get the subset of labels that match the specimen images that are on TRAIN_PATH\n",
    "    labels_subset = label_data.loc[label_data['Id'].isin(specimen_ids)]\n",
    "    \n",
    "    #\n",
    "    # convert labels to trainer format\n",
    "    #\n",
    "    \n",
    "    # set up the list that will contain the list of encoded labels for each specimen id\n",
    "    labels = []\n",
    "    \n",
    "    # loop through each specimen_id\n",
    "    for specimen_id in specimen_ids:\n",
    "        \n",
    "        # split the space separated multi-label into a list of individual labels\n",
    "        split_labels = (labels_subset.loc[labels_subset['Id'] == specimen_id])['Target'].str.split(' ')\n",
    "\n",
    "        # set up a numpy array to receive the encoded label\n",
    "        l = np.zeros(28, dtype=np.uint8)\n",
    "\n",
    "        # turn on the positive columns in the labels array\n",
    "        for label in split_labels:\n",
    "            l[np.uint8(label)] = 1\n",
    "        \n",
    "        labels.append(l)\n",
    "        \n",
    "    return np.array(specimen_ids), np.array(labels)\n",
    "\n",
    "# unit test \n",
    "specimen_ids, labels = get_train_data(TRAIN_PATH, LABEL_PATH)\n",
    "for sid, l in zip(specimen_ids, labels):\n",
    "    print('Specimen Id: {} : Labels: {}'.format(sid, l))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specimen Id: 003170fa-bacd-11e8-b2b8-ac1f6b6435d0 : Labels: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Specimen Id: 00d2a4f8-bad6-11e8-b2b9-ac1f6b6435d0 : Labels: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Specimen Id: 00cfafb0-bacb-11e8-b2b8-ac1f6b6435d0 : Labels: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Specimen Id: 0031820a-baca-11e8-b2b8-ac1f6b6435d0 : Labels: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Specimen Id: 000cce7e-bad4-11e8-b2b8-ac1f6b6435d0 : Labels: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Specimen Id: 0008baca-bad7-11e8-b2b9-ac1f6b6435d0 : Labels: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Specimen Id: 0006faa6-bac7-11e8-b2b7-ac1f6b6435d0 : Labels: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------------------\n",
    "# get the specimen ids to predict\n",
    "# -----------------------------------------------------------\n",
    "def get_predict_data(test_path, output_path):\n",
    "    \n",
    "    # get the list of specimen ids for which there are images\n",
    "    specimen_ids = get_specimen_ids(test_path)\n",
    "    \n",
    "    # get the list of submission specimen ids required\n",
    "    submit_data = pd.read_csv(output_path + '/sample_submission.csv')\n",
    "    \n",
    "    # get the subset of labels that match the specimen images that are on TEST_PATH\n",
    "    submit_subset = submit_data.loc[submit_data['Id'].isin(specimen_ids)]\n",
    "    \n",
    "    # set up the list that will contain the list of encoded labels for each specimen id\n",
    "    predicted_labels = np.zeros((len(specimen_ids), 28), dtype=np.uint8)\n",
    "    \n",
    "    return np.array(specimen_ids), predicted_labels\n",
    "\n",
    "# unit test \n",
    "specimen_ids, labels = get_predict_data(TEST_PATH, OUTPUT_PATH)\n",
    "for sid, l in zip(specimen_ids, labels):\n",
    "    print('Specimen Id: {} : Labels: {}'.format(sid, l))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9473683\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------\n",
    "# calculate the f1 statistic\n",
    "# --------------------------------\n",
    "def f1(y_true, y_pred):\n",
    "    \n",
    "    #y_pred = K.round(y_pred)\n",
    "    y_pred = K.cast(K.greater(K.clip(y_pred, 0, 1), THRESHOLD), K.floatx())\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    \n",
    "    return K.mean(f1)\n",
    "\n",
    "# unit test\n",
    "y_true = K.variable(np.ones(10, np.uint8))\n",
    "y_pred = np.ones(10, np.uint8)\n",
    "y_pred[0] = 0\n",
    "y_pred = K.variable(y_pred)\n",
    "\n",
    "ftest = f1(y_true, y_pred)\n",
    "#ftest = tf.constant(5)\n",
    "\n",
    "init_op = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init_op)\n",
    "print (sess.run(ftest))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.052631676\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------\n",
    "# calculate the f1 loss\n",
    "# --------------------------------\n",
    "\n",
    "def f1_loss(y_true, y_pred):\n",
    "\n",
    "    f = f1(y_true, y_pred)\n",
    "    \n",
    "    return 1 - K.mean(f)\n",
    "\n",
    "# unit test\n",
    "y_true = K.variable(np.ones(10, np.uint8))\n",
    "y_pred = np.ones(10, np.uint8)\n",
    "y_pred[0] = 0\n",
    "y_pred = K.variable(y_pred)\n",
    "\n",
    "ftest = f1_loss(y_true, y_pred)\n",
    "#ftest = tf.constant(5)\n",
    "\n",
    "init_op = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init_op)\n",
    "print (sess.run(ftest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 256, 256, 4)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 256, 256, 4)  16          input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 254, 254, 8)  296         batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_1 (ReLU)                  (None, 254, 254, 8)  0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 254, 254, 8)  32          re_lu_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 252, 252, 8)  584         batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_2 (ReLU)                  (None, 252, 252, 8)  0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 252, 252, 8)  32          re_lu_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 250, 250, 16) 1168        batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_3 (ReLU)                  (None, 250, 250, 16) 0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 250, 250, 16) 64          re_lu_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 125, 125, 16) 0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 125, 125, 16) 0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 125, 125, 16) 2320        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 125, 125, 16) 6416        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 125, 125, 16) 12560       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 125, 125, 16) 272         dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_4 (ReLU)                  (None, 125, 125, 16) 0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_5 (ReLU)                  (None, 125, 125, 16) 0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_6 (ReLU)                  (None, 125, 125, 16) 0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_7 (ReLU)                  (None, 125, 125, 16) 0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 125, 125, 64) 0           re_lu_4[0][0]                    \n",
      "                                                                 re_lu_5[0][0]                    \n",
      "                                                                 re_lu_6[0][0]                    \n",
      "                                                                 re_lu_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 125, 125, 64) 256         concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 62, 62, 64)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 62, 62, 64)   0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 60, 60, 32)   18464       dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_8 (ReLU)                  (None, 60, 60, 32)   0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 60, 60, 32)   128         re_lu_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 30, 30, 32)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 30, 30, 32)   0           max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 28, 28, 64)   18496       dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_9 (ReLU)                  (None, 28, 28, 64)   0           conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 28, 28, 64)   256         re_lu_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 14, 14, 64)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 14, 14, 64)   0           max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 12, 12, 128)  73856       dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_10 (ReLU)                 (None, 12, 12, 128)  0           conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 12, 12, 128)  512         re_lu_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 6, 6, 128)    0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 6, 6, 128)    0           max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 4608)         0           dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 4608)         0           flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 28)           129052      dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_11 (ReLU)                 (None, 28)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 28)           112         re_lu_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 28)           0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 28)           812         dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 28)           0           dense_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 265,704\n",
      "Trainable params: 265,000\n",
      "Non-trainable params: 704\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------\n",
    "# create the model\n",
    "# ------------------------------\n",
    "def create_model(input_shape):\n",
    "\n",
    "    dropRate = 0.25\n",
    "    \n",
    "    init = Input(input_shape)\n",
    "    x = BatchNormalization(axis=-1)(init)\n",
    "    x = Conv2D(8, (3, 3))(x)\n",
    "    x = ReLU()(x)\n",
    "    x = BatchNormalization(axis=-1)(x)\n",
    "    x = Conv2D(8, (3, 3))(x)\n",
    "    x = ReLU()(x)\n",
    "    x = BatchNormalization(axis=-1)(x)\n",
    "    x = Conv2D(16, (3, 3))(x)\n",
    "    x = ReLU()(x)\n",
    "    x = BatchNormalization(axis=-1)(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Dropout(dropRate)(x)\n",
    "    c1 = Conv2D(16, (3, 3), padding='same')(x)\n",
    "    c1 = ReLU()(c1)\n",
    "    c2 = Conv2D(16, (5, 5), padding='same')(x)\n",
    "    c2 = ReLU()(c2)\n",
    "    c3 = Conv2D(16, (7, 7), padding='same')(x)\n",
    "    c3 = ReLU()(c3)\n",
    "    c4 = Conv2D(16, (1, 1), padding='same')(x)\n",
    "    c4 = ReLU()(c4)\n",
    "    x = Concatenate()([c1, c2, c3, c4])\n",
    "    x = BatchNormalization(axis=-1)(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Dropout(dropRate)(x)\n",
    "    x = Conv2D(32, (3, 3))(x)\n",
    "    x = ReLU()(x)\n",
    "    x = BatchNormalization(axis=-1)(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Dropout(dropRate)(x)\n",
    "    x = Conv2D(64, (3, 3))(x)\n",
    "    x = ReLU()(x)\n",
    "    x = BatchNormalization(axis=-1)(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Dropout(dropRate)(x)\n",
    "    x = Conv2D(128, (3, 3))(x)\n",
    "    x = ReLU()(x)\n",
    "    x = BatchNormalization(axis=-1)(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Dropout(dropRate)(x)\n",
    "    #x = Conv2D(256, (1, 1), activation='relu')(x)\n",
    "    #x = BatchNormalization(axis=-1)(x)\n",
    "    #x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    #x = Dropout(0.25)(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(28)(x)\n",
    "    x = ReLU()(x)\n",
    "    x = BatchNormalization(axis=-1)(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    x = Dense(28)(x)\n",
    "    x = Activation('sigmoid')(x)\n",
    "    \n",
    "    model = Model(init, x)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# unit test\n",
    "model = create_model(SHAPE)\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer=Adam(1e-03),\n",
    "    metrics=['acc',f1])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7,)\n",
      "(3,)\n",
      "4\n",
      "2\n",
      "['001bcdd2-bbb2-11e8-b2ba-ac1f6b6435d0'\n",
      " 'fc84a97c-bbad-11e8-b2ba-ac1f6b6435d0'\n",
      " '001838f8-bbca-11e8-b2bc-ac1f6b6435d0'] [[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# get data\n",
    "def get_data(test_size=0.1):\n",
    "    \n",
    "    specimen_ids, labels = get_train_data(TRAIN_PATH, LABEL_PATH)\n",
    "    train_set_sids, val_set_sids, train_set_lbls, val_set_lbls = train_test_split(specimen_ids, labels, test_size=test_size, random_state=SEED)\n",
    "    \n",
    "    return train_set_sids, val_set_sids, train_set_lbls, val_set_lbls\n",
    "\n",
    "# unit test\n",
    "train_set_sids, val_set_sids, train_set_lbls, val_set_lbls = get_data(test_size=0.3)\n",
    "print (train_set_sids.shape)\n",
    "print (val_set_sids.shape)\n",
    "\n",
    "# create data generators\n",
    "tg = HproteinDataGenerator(TRAIN_PATH, train_set_sids, train_set_lbls)\n",
    "vg = HproteinDataGenerator(TRAIN_PATH, val_set_sids, val_set_lbls)\n",
    "print(len(tg))\n",
    "print(len(vg))\n",
    "print (val_set_sids, val_set_lbls)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint('./base.model', monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='min', period=1)\n",
    "reduceLROnPlato = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1, mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "3/4 [=====================>........] - ETA: 2s - loss: 0.8052 - acc: 0.6310 - f1: 0.0635before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "4/4 [==============================] - 11s 3s/step - loss: 0.8161 - acc: 0.5842 - f1: 0.0776 - val_loss: 1.4204 - val_acc: 0.4821 - val_f1: 0.0466\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.42041, saving model to ./base.model\n",
      "Epoch 2/5\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.7467 - acc: 0.6607 - f1: 0.0873before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "4/4 [==============================] - 7s 2s/step - loss: 0.7489 - acc: 0.6097 - f1: 0.0776 - val_loss: 1.0154 - val_acc: 0.4911 - val_f1: 0.0516\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.42041 to 1.01543, saving model to ./base.model\n",
      "Epoch 3/5\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.7522 - acc: 0.6369 - f1: 0.0794before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "4/4 [==============================] - 7s 2s/step - loss: 0.7613 - acc: 0.5867 - f1: 0.0776 - val_loss: 0.7397 - val_acc: 0.5149 - val_f1: 0.0516\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.01543 to 0.73969, saving model to ./base.model\n",
      "Epoch 4/5\n",
      "3/4 [=====================>........] - ETA: 1s - loss: 0.7102 - acc: 0.6845 - f1: 0.0873before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "4/4 [==============================] - 7s 2s/step - loss: 0.7073 - acc: 0.6602 - f1: 0.0776 - val_loss: 0.7117 - val_acc: 0.5268 - val_f1: 0.0516\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.73969 to 0.71173, saving model to ./base.model\n",
      "Epoch 5/5\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.7162 - acc: 0.6548 - f1: 0.0794before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.7215 - acc: 0.6153 - f1: 0.0776 - val_loss: 0.7004 - val_acc: 0.5625 - val_f1: 0.0516\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.71173 to 0.70044, saving model to ./base.model\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "\n",
    "use_multiprocessing = False # DO NOT COMBINE MULTIPROCESSING WITH CACHE! \n",
    "workers = 1 # DO NOT COMBINE MULTIPROCESSING WITH CACHE! \n",
    "\n",
    "hist = model.fit_generator(\n",
    "    tg,\n",
    "    steps_per_epoch=len(tg),\n",
    "    validation_data=vg,\n",
    "    validation_steps=8,\n",
    "    epochs=epochs,\n",
    "    use_multiprocessing=use_multiprocessing,\n",
    "    workers=workers,\n",
    "    verbose=1,\n",
    "    callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1319155c0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(15,5))\n",
    "ax[0].set_title('loss')\n",
    "ax[0].plot(hist.epoch, hist.history[\"loss\"], label=\"Train loss\")\n",
    "ax[0].plot(hist.epoch, hist.history[\"val_loss\"], label=\"Validation loss\")\n",
    "ax[1].set_title('acc')\n",
    "ax[1].plot(hist.epoch, hist.history[\"f1\"], label=\"Train F1\")\n",
    "ax[1].plot(hist.epoch, hist.history[\"val_f1\"], label=\"Validation F1\")\n",
    "ax[0].legend()\n",
    "ax[1].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = load_model('./base.model', custom_objects={'f1': f1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "(3, 28)\n",
      "(3, 28)\n",
      "[[0.63810885 0.46370673 0.75451058 0.29712042 0.71356064 0.652767\n",
      "  0.45021841 0.34775525 0.3166737  0.49896729 0.54922265 0.28867757\n",
      "  0.50651926 0.19148538 0.59472281 0.45897526 0.32912576 0.55866408\n",
      "  0.30970293 0.5430851  0.38914403 0.48778111 0.5884304  0.42739064\n",
      "  0.55356371 0.68081826 0.61997479 0.4846552 ]\n",
      " [0.66696382 0.21538499 0.78596818 0.44345728 0.38576579 0.59988111\n",
      "  0.21875234 0.23086797 0.30630246 0.67965525 0.3412073  0.50616521\n",
      "  0.30166525 0.59035993 0.71627384 0.48914969 0.3471128  0.57559472\n",
      "  0.61800528 0.45185369 0.54963577 0.76760244 0.76543814 0.26402339\n",
      "  0.64473623 0.80272824 0.526636   0.55886734]\n",
      " [0.50789738 0.31963843 0.79626781 0.42980447 0.45050487 0.54751605\n",
      "  0.31150469 0.21466738 0.42233914 0.70639545 0.50356603 0.43811908\n",
      "  0.39068663 0.51032734 0.62243038 0.35355952 0.37051031 0.56559795\n",
      "  0.62134957 0.59239811 0.53450423 0.78280741 0.79314005 0.14820772\n",
      "  0.6769895  0.8178528  0.48145223 0.66761637]]\n"
     ]
    }
   ],
   "source": [
    "val_predictions = np.empty((0, 28))\n",
    "val_labels = np.empty((0, 28))\n",
    "for i in range(len(vg)):\n",
    "    image, label = vg[i]\n",
    "    scores = final_model.predict(image)\n",
    "    #print('scores -> {}'.format(scores))\n",
    "    #print('label  -> {}'.format(label))\n",
    "    val_predictions = np.append(val_predictions, scores, axis=0)\n",
    "    val_labels = np.append(val_labels, label, axis=0)\n",
    "print(val_predictions.shape)\n",
    "print(val_labels.shape)\n",
    "print(val_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/farrar/py3.6.5/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/Users/farrar/py3.6.5/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 28)\n",
      "[[0.8 0.  0.  ... 0.  0.  0. ]\n",
      " [0.8 0.  0.  ... 0.  0.  0. ]\n",
      " [0.8 0.  0.  ... 0.  0.  0. ]\n",
      " ...\n",
      " [0.  0.  0.  ... 0.  0.  0. ]\n",
      " [0.  0.  0.  ... 0.  0.  0. ]\n",
      " [0.  0.  0.  ... 0.  0.  0. ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "rng = np.arange(0, 1, 0.001)\n",
    "fscores = np.zeros((rng.shape[0], 28))\n",
    "for j,k in enumerate(rng):\n",
    "    for i in range(28):\n",
    "        p = np.array(val_predictions[:,i]>k, dtype=np.int8)\n",
    "        #print('p -> {}'.format(p))\n",
    "        #print('v -> {}'.format(val_predictions[:,i]))\n",
    "        #print('l -> {}'.format(val_labels[:,i]))\n",
    "        score = f1_score(val_labels[:,i], p, average='binary')\n",
    "        #print(score)\n",
    "        fscores[j,i] = score\n",
    "        \n",
    "        \n",
    "print (fscores.shape)\n",
    "print (fscores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual F1-scores for each class:\n",
      "[1.  0.  0.  0.  0.5 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 1.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]\n",
      "Macro F1-score CV = 0.08928571428571429\n"
     ]
    }
   ],
   "source": [
    "print('Individual F1-scores for each class:')\n",
    "print(np.max(fscores, axis=0))\n",
    "print('Macro F1-score CV =', np.mean(np.max(fscores, axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability threshold maximizing CV F1-score for each class:\n",
      "[0.508 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.619 0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.   ]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(rng, fscores)\n",
    "p_threshold = np.empty(28)\n",
    "for i in range(28):\n",
    "    p_threshold[i] = rng[np.where(fscores[:,i] == np.max(fscores[:,i]))[0][0]]\n",
    "print('Probability threshold maximizing CV F1-score for each class:')\n",
    "print(p_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "1\n",
      "['003170fa-bacd-11e8-b2b8-ac1f6b6435d0'\n",
      " '00d2a4f8-bad6-11e8-b2b9-ac1f6b6435d0'\n",
      " '00cfafb0-bacb-11e8-b2b8-ac1f6b6435d0'\n",
      " '0031820a-baca-11e8-b2b8-ac1f6b6435d0'\n",
      " '000cce7e-bad4-11e8-b2b8-ac1f6b6435d0'\n",
      " '0008baca-bad7-11e8-b2b9-ac1f6b6435d0'\n",
      " '0006faa6-bac7-11e8-b2b7-ac1f6b6435d0'] [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "predict_set_sids, predict_set_lbls = get_predict_data(TEST_PATH, OUTPUT_PATH)\n",
    "pg = HproteinDataGenerator(TEST_PATH, predict_set_sids, predict_set_lbls)\n",
    "\n",
    "print(len(pg))\n",
    "print(pg.last_batch_padding)\n",
    "print (predict_set_sids, predict_set_lbls)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "before -> (512, 512, 4)\n",
      "after  -> (256, 256, 4)\n",
      "blank rows shape (1, 256, 256, 4)\n",
      "Images Shape After: (2, 256, 256, 4)\n",
      "[[7.50738919e-01 7.73247302e-01 3.74477237e-01 5.62149763e-01\n",
      "  7.70589769e-01 3.59674722e-01 8.38983059e-02 8.18451822e-01\n",
      "  4.93685529e-02 1.83787376e-01 5.62640667e-01 7.35400319e-01\n",
      "  9.74705517e-01 1.92737088e-01 5.92667520e-01 6.95811868e-01\n",
      "  7.84474611e-01 8.80571008e-01 5.34654677e-01 4.66988623e-01\n",
      "  9.03278589e-01 2.32518569e-01 3.92757297e-01 2.41186135e-02\n",
      "  9.83288959e-02 4.12611216e-02 8.58493447e-01 2.87646174e-01]\n",
      " [2.24437639e-01 6.31296933e-01 1.51013926e-01 8.71016800e-01\n",
      "  2.92944964e-02 1.66141137e-01 5.19282036e-02 6.86921477e-01\n",
      "  1.70262411e-01 8.36106598e-01 3.88055563e-01 9.83197749e-01\n",
      "  9.86945093e-01 9.69163358e-01 9.54391599e-01 5.61569393e-01\n",
      "  8.96319449e-01 7.16942191e-01 9.97667193e-01 3.38249773e-01\n",
      "  9.79960382e-01 8.92004550e-01 8.45976472e-01 2.32092789e-04\n",
      "  1.05616063e-01 1.45723552e-01 8.75157416e-01 3.50731790e-01]\n",
      " [5.61922789e-01 5.88858485e-01 4.47496772e-01 9.45133686e-01\n",
      "  1.43839449e-01 7.15493113e-02 2.06487123e-02 6.41858354e-02\n",
      "  3.13585818e-01 6.21755540e-01 3.22207779e-01 9.89118576e-01\n",
      "  9.54500198e-01 9.95667338e-01 8.53120804e-01 6.53573692e-01\n",
      "  9.70290184e-01 3.50308925e-01 9.98572946e-01 5.43456197e-01\n",
      "  9.55573797e-01 9.89210367e-01 9.72413063e-01 8.68947463e-05\n",
      "  2.92862207e-03 1.07228935e-01 6.55320942e-01 2.27236375e-01]\n",
      " [7.05070198e-01 2.50889391e-01 5.94378293e-01 6.42157018e-01\n",
      "  2.24945277e-01 3.37416828e-01 2.67461091e-01 5.03355682e-01\n",
      "  3.60976964e-01 4.98709023e-01 3.70637268e-01 8.20309520e-01\n",
      "  4.21031415e-01 7.05947995e-01 4.49218720e-01 4.07183647e-01\n",
      "  4.81941044e-01 5.99961996e-01 8.67429256e-01 2.95636415e-01\n",
      "  8.04292619e-01 8.33326161e-01 5.02355695e-01 8.84425789e-02\n",
      "  8.46235156e-01 8.33855152e-01 5.36447465e-01 7.57324874e-01]\n",
      " [3.14542830e-01 8.75601470e-01 7.25764185e-02 4.81003195e-01\n",
      "  3.09305638e-01 7.24344432e-01 5.31161904e-01 9.00797307e-01\n",
      "  1.19627453e-01 4.59731281e-01 5.76323271e-01 7.28821397e-01\n",
      "  9.91066158e-01 2.89038718e-01 9.04094934e-01 6.42182589e-01\n",
      "  7.25487411e-01 5.53034961e-01 8.64440262e-01 6.14775121e-01\n",
      "  7.40294576e-01 2.66696215e-01 4.13602322e-01 4.83663604e-02\n",
      "  6.19641766e-02 6.88233674e-02 9.57625747e-01 1.60029396e-01]\n",
      " [5.80826104e-01 6.14617944e-01 2.98754483e-01 7.75019228e-01\n",
      "  2.21331477e-01 1.97660774e-01 5.48290275e-02 6.90262377e-01\n",
      "  1.18932314e-01 7.08896995e-01 5.77671647e-01 9.83767033e-01\n",
      "  9.80674922e-01 9.40215230e-01 8.83555651e-01 6.31215334e-01\n",
      "  9.22308505e-01 7.57148504e-01 9.95996356e-01 3.07163954e-01\n",
      "  9.83199179e-01 8.13662827e-01 8.79528701e-01 1.94922381e-04\n",
      "  4.01835814e-02 6.21393621e-02 9.11402106e-01 2.45519936e-01]\n",
      " [6.21833622e-01 4.35160577e-01 7.41484225e-01 2.72398710e-01\n",
      "  7.27562487e-01 6.57297790e-01 3.96610618e-01 3.45143914e-01\n",
      "  2.77376354e-01 4.96429384e-01 5.12191713e-01 3.11377913e-01\n",
      "  5.31862319e-01 1.92852020e-01 5.65081120e-01 4.81992781e-01\n",
      "  3.03343982e-01 5.87767482e-01 3.04731727e-01 5.21881282e-01\n",
      "  3.93349260e-01 5.02582014e-01 5.75609148e-01 4.21633691e-01\n",
      "  5.77290356e-01 6.85919344e-01 5.63662887e-01 4.88349557e-01]\n",
      " [4.11264002e-01 6.49197221e-01 2.04826578e-01 9.11643326e-01\n",
      "  9.53359306e-02 7.66049922e-02 4.20521609e-02 3.53366256e-01\n",
      "  2.67634541e-01 8.03321064e-01 5.55132747e-01 9.90529954e-01\n",
      "  9.89263713e-01 9.96487021e-01 9.01026368e-01 6.53395712e-01\n",
      "  9.68733907e-01 5.84841907e-01 9.99305725e-01 5.44336319e-01\n",
      "  9.63671803e-01 9.61241663e-01 9.70177531e-01 3.01394612e-05\n",
      "  3.67696071e-03 6.23356178e-02 8.70325387e-01 1.86406866e-01]]\n"
     ]
    }
   ],
   "source": [
    "predictions = np.zeros((predict_set_sids.shape[0] + pg.last_batch_padding, 28))\n",
    "for i in range(len(pg)):\n",
    "    images, labels = pg[i]\n",
    "    if (images.shape[0] < pg.batch_size):\n",
    "        blank_rows = np.zeros((pg.last_batch_padding, pg.shape[0], pg.shape[1], pg.shape[2]))\n",
    "        print('blank rows shape {}'.format(blank_rows.shape))\n",
    "        images = np.append(images, blank_rows, axis=0)\n",
    "        print ('Images Shape After: {}'.format(images.shape))\n",
    "    score = final_model.predict(images)\n",
    "    predictions[i*BATCH_SIZE:i*BATCH_SIZE+images.shape[0]] = score\n",
    "    \n",
    "print (predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the list of submission specimen ids required\n",
    "submit_data = pd.read_csv(OUTPUT_PATH + '/sample_submission.csv')\n",
    "\n",
    "# get the subset of labels that match the specimen images that are on TEST_PATH\n",
    "submit_data = submit_data.loc[submit_data['Id'].isin(specimen_ids)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 28)\n"
     ]
    }
   ],
   "source": [
    "prediction_str = []\n",
    "print(predictions.shape)\n",
    "predictions = predictions[:predictions.shape[0] - pg.last_batch_padding, :]\n",
    "for i in range(predictions.shape[0]):\n",
    "    submit_str = ' '\n",
    "    for j in range(predictions.shape[1]):\n",
    "        if predictions[i,j] >= p_threshold[j]:\n",
    "            submit_str += str(j) + ' '\n",
    "            \n",
    "    prediction_str.append(submit_str)\n",
    "    \n",
    "submit_data['Predicted'] = np.array(prediction_str)\n",
    "\n",
    "submit_data.to_csv(OUTPUT_PATH + '/submit_3434.csv', index=False)\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndef random_crop(image, crop_size=256, original_size=512):\\n    \\n    # get a pair of random coordinates that will provide for an image of crop_size\\n    x_origin = random.randint(0, original_size - crop_size)\\n    y_origin = random.randint(0, original_size - crop_size)\\n    \\n    crop = image[x_origin : x_origin + crop_size, y_origin : y_origin + crop_size, :]\\n    \\n    return crop\\n\\n# unit test\\nimg, lbl = tg[0]\\nimage = img[i]\\ncrop = random_crop(image, crop_size=128, original_size=256)\\nprint('Shape before -> {}'.format(image.shape))\\nprint('Shape after  -> {}'.format(crop.shape))\\n\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def random_crop(image, crop_size=256, original_size=512):\n",
    "    \n",
    "    # get a pair of random coordinates that will provide for an image of crop_size\n",
    "    x_origin = random.randint(0, original_size - crop_size)\n",
    "    y_origin = random.randint(0, original_size - crop_size)\n",
    "    \n",
    "    crop = image[x_origin : x_origin + crop_size, y_origin : y_origin + crop_size, :]\n",
    "    \n",
    "    return crop\n",
    "\n",
    "# unit test\n",
    "img, lbl = tg[0]\n",
    "image = img[i]\n",
    "crop = random_crop(image, crop_size=128, original_size=256)\n",
    "print('Shape before -> {}'.format(image.shape))\n",
    "print('Shape after  -> {}'.format(crop.shape))\n",
    "'''    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
