{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/farrar/py3.6.5/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# KAGGLE ---------------------\n",
    "import sys\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.utils import Sequence\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import imgaug as ia\n",
    "from imgaug import augmenters as iaa\n",
    "import cv2\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, load_model, Model\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense, Input, Conv2D, MaxPooling2D, BatchNormalization, Concatenate, ReLU, LeakyReLU, GlobalAveragePooling2D\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\n",
    "from keras import metrics\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import backend as K\n",
    "import keras\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MINE -----------------------------------\n",
    "import hprotein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KAGGLE ---------------------------------\n",
    "BATCH_SIZE = 2\n",
    "SEED = 777\n",
    "SHAPE = (512, 512, 4)\n",
    "DIR = '../input'\n",
    "VAL_RATIO = 0.3 # 10 % as validation\n",
    "THRESHOLD = 0.5 # due to different cost of True Positive vs False Positive, this is the probability threshold to predict the class as 'yes'\n",
    "\n",
    "ia.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MINE -----------------------------------\n",
    "# constants\n",
    "TRAIN_PATH = '../stage1_train'\n",
    "TEST_PATH = '../stage1_test'\n",
    "LABEL_PATH = '../stage1_labels/train_short.csv'\n",
    "OUTPUT_PATH = '../stage1_submit'\n",
    "COLORS = ['red','green', 'blue', 'yellow']\n",
    "IMAGE_SIZE = 512\n",
    "CROP_SIZE = 512\n",
    "BATCH_SIZE = 2\n",
    "SHAPE = (CROP_SIZE, CROP_SIZE, 4)\n",
    "THRESHOLD = 0.05\n",
    "SEED = 42\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "['../stage1_train/000c99ba-bba4-11e8-b2b9-ac1f6b6435d0'\n",
      " '../stage1_train/001838f8-bbca-11e8-b2bc-ac1f6b6435d0'\n",
      " '../stage1_train/001bcdd2-bbb2-11e8-b2ba-ac1f6b6435d0'\n",
      " '../stage1_train/0020af02-bbba-11e8-b2ba-ac1f6b6435d0'\n",
      " '../stage1_train/002daad6-bbc9-11e8-b2bc-ac1f6b6435d0'\n",
      " '../stage1_train/fb4c1fac-bbaa-11e8-b2ba-ac1f6b6435d0'\n",
      " '../stage1_train/fc84a97c-bbad-11e8-b2ba-ac1f6b6435d0'\n",
      " '../stage1_train/fea6e496-bbbb-11e8-b2ba-ac1f6b6435d0'\n",
      " '../stage1_train/ffeae6f0-bbc9-11e8-b2bc-ac1f6b6435d0'\n",
      " '../stage1_train/fffe0ffe-bbc0-11e8-b2bb-ac1f6b6435d0']\n",
      "10\n",
      "<class 'numpy.float64'>\n",
      "1.0\n",
      "[[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 1. 0. 0.]\n",
      " [1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# KAGGLE ---------------------\n",
    "def getTrainDataset():\n",
    "    \n",
    "    # path_to_train = DIR + '/train/'\n",
    "    # data = pd.read_csv(DIR + '/train.csv')\n",
    "\n",
    "    path_to_train = TRAIN_PATH\n",
    "    data = pd.read_csv(LABEL_PATH)\n",
    "    \n",
    "    paths = []\n",
    "    labels = []\n",
    "    \n",
    "    for name, lbl in zip(data['Id'], data['Target'].str.split(' ')):\n",
    "        y = np.zeros(28)\n",
    "        for key in lbl:\n",
    "            y[int(key)] = 1\n",
    "        paths.append(os.path.join(path_to_train, name))\n",
    "        labels.append(y)\n",
    "\n",
    "    return np.array(paths), np.array(labels)\n",
    "\n",
    "# unit test ------------------------------------\n",
    "p, l = getTrainDataset()\n",
    "print (len(p))\n",
    "print (p)\n",
    "print (len(l))\n",
    "print(type(l[0][1]))\n",
    "print((l[0][1]))\n",
    "print (l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "['000c99ba-bba4-11e8-b2b9-ac1f6b6435d0'\n",
      " '001bcdd2-bbb2-11e8-b2ba-ac1f6b6435d0'\n",
      " '0020af02-bbba-11e8-b2ba-ac1f6b6435d0'\n",
      " 'fb4c1fac-bbaa-11e8-b2ba-ac1f6b6435d0'\n",
      " 'fc84a97c-bbad-11e8-b2ba-ac1f6b6435d0'\n",
      " 'fea6e496-bbbb-11e8-b2ba-ac1f6b6435d0'\n",
      " 'fffe0ffe-bbc0-11e8-b2bb-ac1f6b6435d0']\n",
      "7\n",
      "<class 'numpy.float64'>\n",
      "1.0\n",
      "[[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 1. 0. 0.]\n",
      " [1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# MINE -----------------------------------\n",
    "p_me, l_me = hprotein.get_data(TRAIN_PATH, LABEL_PATH, mode='train', filter_ids=hprotein.mini_validate_set)\n",
    "print (len(p_me))\n",
    "print (p_me)\n",
    "print (len(l_me))\n",
    "print(type(l_me[0][1]))\n",
    "print((l_me[0][1]))\n",
    "print (l_me)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "['../stage1_test/00cfafb0-bacb-11e8-b2b8-ac1f6b6435d0'\n",
      " '../stage1_test/00d2a4f8-bad6-11e8-b2b9-ac1f6b6435d0'\n",
      " '../stage1_test/000cce7e-bad4-11e8-b2b8-ac1f6b6435d0'\n",
      " '../stage1_test/0006faa6-bac7-11e8-b2b7-ac1f6b6435d0'\n",
      " '../stage1_test/0008baca-bad7-11e8-b2b9-ac1f6b6435d0'\n",
      " '../stage1_test/003170fa-bacd-11e8-b2b8-ac1f6b6435d0'\n",
      " '../stage1_test/0031820a-baca-11e8-b2b8-ac1f6b6435d0']\n",
      "7\n",
      "[[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# KAGGLE ---------------------\n",
    "def getTestDataset():\n",
    "    \n",
    "    #path_to_test = DIR + '/test/'\n",
    "    #data = pd.read_csv(DIR + '/sample_submission.csv')\n",
    "    path_to_test = TEST_PATH\n",
    "    data = pd.read_csv(OUTPUT_PATH + '/sample_submission_short.csv')\n",
    "\n",
    "\n",
    "    paths = []\n",
    "    labels = []\n",
    "    \n",
    "    for name in data['Id']:\n",
    "        y = np.ones(28)\n",
    "        paths.append(os.path.join(path_to_test, name))\n",
    "        labels.append(y)\n",
    "\n",
    "    return np.array(paths), np.array(labels)\n",
    "\n",
    "# unit test ------------------------------------\n",
    "p_test, l_test = getTestDataset()\n",
    "print (len(p_test))\n",
    "print (p_test)\n",
    "print (len(l_test))\n",
    "print (l_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "['0008baca-bad7-11e8-b2b9-ac1f6b6435d0'\n",
      " '00cfafb0-bacb-11e8-b2b8-ac1f6b6435d0'\n",
      " '000cce7e-bad4-11e8-b2b8-ac1f6b6435d0'\n",
      " '0006faa6-bac7-11e8-b2b7-ac1f6b6435d0'\n",
      " '0031820a-baca-11e8-b2b8-ac1f6b6435d0'\n",
      " '00d2a4f8-bad6-11e8-b2b9-ac1f6b6435d0'\n",
      " '003170fa-bacd-11e8-b2b8-ac1f6b6435d0']\n",
      "7\n",
      "[[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# MINE -----------------------------------\n",
    "p_me_test, l_me_test = hprotein.get_data(TEST_PATH, OUTPUT_PATH, mode='test', filter_ids=None)\n",
    "print (len(p_me_test))\n",
    "print (p_me_test)\n",
    "print (len(l_me_test))\n",
    "print (l_me_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KAGGLE -----------------------------------\n",
    "class ProteinDataGenerator(keras.utils.Sequence):\n",
    "            \n",
    "    def __init__(self, paths, labels, batch_size, shape, shuffle = False, use_cache = False, augment = False):\n",
    "        self.paths, self.labels = paths, labels\n",
    "        self.batch_size = batch_size\n",
    "        self.shape = shape\n",
    "        self.shuffle = shuffle\n",
    "        self.use_cache = use_cache\n",
    "        self.augment = augment\n",
    "        if use_cache == True:\n",
    "            self.cache = np.zeros((paths.shape[0], shape[0], shape[1], shape[2]), dtype=np.float16)\n",
    "            self.is_cached = np.zeros((paths.shape[0]))\n",
    "        self.on_epoch_end()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.paths) / float(self.batch_size)))\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        indexes = self.indexes[idx * self.batch_size : (idx+1) * self.batch_size]\n",
    "\n",
    "        paths = self.paths[indexes]\n",
    "        X = np.zeros((paths.shape[0], self.shape[0], self.shape[1], self.shape[2]))\n",
    "        # Generate data\n",
    "        if self.use_cache == True:\n",
    "            X = self.cache[indexes]\n",
    "            for i, path in enumerate(paths[np.where(self.is_cached[indexes] == 0)]):\n",
    "                image = self.__load_image(path)\n",
    "                self.is_cached[indexes[i]] = 1\n",
    "                self.cache[indexes[i]] = image\n",
    "                X[i] = image\n",
    "        else:\n",
    "            for i, path in enumerate(paths):\n",
    "                X[i] = self.__load_image(path)\n",
    "\n",
    "        y = self.labels[indexes]\n",
    "        \n",
    "        if self.augment == True:\n",
    "            seq = iaa.Sequential([\n",
    "                iaa.OneOf([\n",
    "                    iaa.Fliplr(0.5), # horizontal flips\n",
    "                    iaa.Crop(percent=(0, 0.1)), # random crops\n",
    "                    # Small gaussian blur with random sigma between 0 and 0.5.\n",
    "                    # But we only blur about 50% of all images.\n",
    "                    iaa.Sometimes(0.5,\n",
    "                        iaa.GaussianBlur(sigma=(0, 0.5))\n",
    "                    ),\n",
    "                    # Strengthen or weaken the contrast in each image.\n",
    "                    iaa.ContrastNormalization((0.75, 1.5)),\n",
    "                    # Add gaussian noise.\n",
    "                    # For 50% of all images, we sample the noise once per pixel.\n",
    "                    # For the other 50% of all images, we sample the noise per pixel AND\n",
    "                    # channel. This can change the color (not only brightness) of the\n",
    "                    # pixels.\n",
    "                    iaa.AdditiveGaussianNoise(loc=0, scale=(0.0, 0.05*255), per_channel=0.5),\n",
    "                    # Make some images brighter and some darker.\n",
    "                    # In 20% of all cases, we sample the multiplier once per channel,\n",
    "                    # which can end up changing the color of the images.\n",
    "                    iaa.Multiply((0.8, 1.2), per_channel=0.2),\n",
    "                    # Apply affine transformations to each image.\n",
    "                    # Scale/zoom them, translate/move them, rotate them and shear them.\n",
    "                    iaa.Affine(\n",
    "                        scale={\"x\": (0.8, 1.2), \"y\": (0.8, 1.2)},\n",
    "                        translate_percent={\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)},\n",
    "                        rotate=(-180, 180),\n",
    "                        shear=(-8, 8)\n",
    "                    )\n",
    "                ])], random_order=True)\n",
    "        \n",
    "            X = np.concatenate((X, seq.augment_images(X), seq.augment_images(X), seq.augment_images(X)), 0)\n",
    "            y = np.concatenate((y, y, y, y), 0)\n",
    "        \n",
    "        return X, y\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        \n",
    "        # Updates indexes after each epoch\n",
    "        self.indexes = np.arange(len(self.paths))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __iter__(self):\n",
    "        \"\"\"Create a generator that iterate over the Sequence.\"\"\"\n",
    "        for item in (self[i] for i in range(len(self))):\n",
    "            yield item\n",
    "            \n",
    "    def __load_image(self, path):\n",
    "        R = Image.open(path + '_red.png')\n",
    "        G = Image.open(path + '_green.png')\n",
    "        B = Image.open(path + '_blue.png')\n",
    "        Y = Image.open(path + '_yellow.png')\n",
    "\n",
    "        im = np.stack((\n",
    "            np.array(R), \n",
    "            np.array(G), \n",
    "            np.array(B),\n",
    "            np.array(Y)), -1)\n",
    "\n",
    "        #print('Before resize -> {}'.format(im.shape))\n",
    "        im = cv2.resize(im, (SHAPE[0], SHAPE[1]))\n",
    "        #print('After resize -> {}'.format(im.shape))\n",
    "        im = np.divide(im, 255)\n",
    "        return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10,) (10, 28)\n",
      "(7,) (7, 28) (3,) (3, 28)\n",
      "['../stage1_train/000c99ba-bba4-11e8-b2b9-ac1f6b6435d0'\n",
      " '../stage1_train/001838f8-bbca-11e8-b2bc-ac1f6b6435d0'\n",
      " '../stage1_train/001bcdd2-bbb2-11e8-b2ba-ac1f6b6435d0'\n",
      " '../stage1_train/0020af02-bbba-11e8-b2ba-ac1f6b6435d0'\n",
      " '../stage1_train/002daad6-bbc9-11e8-b2bc-ac1f6b6435d0'\n",
      " '../stage1_train/fb4c1fac-bbaa-11e8-b2ba-ac1f6b6435d0'\n",
      " '../stage1_train/fc84a97c-bbad-11e8-b2ba-ac1f6b6435d0']\n",
      "[[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]]\n",
      "['../stage1_train/fea6e496-bbbb-11e8-b2ba-ac1f6b6435d0'\n",
      " '../stage1_train/ffeae6f0-bbc9-11e8-b2bc-ac1f6b6435d0'\n",
      " '../stage1_train/fffe0ffe-bbc0-11e8-b2bb-ac1f6b6435d0']\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 1. 0. 0.]\n",
      " [1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# KAGGLE -----------------------------------\n",
    "paths, labels = getTrainDataset()\n",
    "\n",
    "# divide to \n",
    "keys = np.arange(paths.shape[0], dtype=np.int)  \n",
    "np.random.seed(SEED)\n",
    "np.random.shuffle(keys)\n",
    "lastTrainIndex = int((1-VAL_RATIO) * paths.shape[0])\n",
    "\n",
    "pathsTrain = paths[0:lastTrainIndex]\n",
    "labelsTrain = labels[0:lastTrainIndex]\n",
    "pathsVal = paths[lastTrainIndex:]\n",
    "labelsVal = labels[lastTrainIndex:]\n",
    "\n",
    "print(paths.shape, labels.shape)\n",
    "print(pathsTrain.shape, labelsTrain.shape, pathsVal.shape, labelsVal.shape)\n",
    "print(pathsTrain)\n",
    "print(labelsTrain)\n",
    "print(pathsVal)\n",
    "print(labelsVal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7,) (7, 28) (3,) (3, 28)\n",
      "['000c99ba-bba4-11e8-b2b9-ac1f6b6435d0'\n",
      " '001bcdd2-bbb2-11e8-b2ba-ac1f6b6435d0'\n",
      " '0020af02-bbba-11e8-b2ba-ac1f6b6435d0'\n",
      " 'fb4c1fac-bbaa-11e8-b2ba-ac1f6b6435d0'\n",
      " 'fc84a97c-bbad-11e8-b2ba-ac1f6b6435d0'\n",
      " 'fea6e496-bbbb-11e8-b2ba-ac1f6b6435d0'\n",
      " 'fffe0ffe-bbc0-11e8-b2bb-ac1f6b6435d0']\n",
      "[[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 1. 0. 0.]\n",
      " [1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]]\n",
      "['001838f8-bbca-11e8-b2bc-ac1f6b6435d0'\n",
      " '002daad6-bbc9-11e8-b2bc-ac1f6b6435d0'\n",
      " 'ffeae6f0-bbc9-11e8-b2bc-ac1f6b6435d0']\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# MINE -----------------------------------\n",
    "p_v_me, l_v_me = hprotein.get_data(TRAIN_PATH, LABEL_PATH, mode='mini-validate', filter_ids=hprotein.mini_validate_set)\n",
    "print(p_me.shape, l_me.shape, p_v_me.shape, l_v_me.shape)\n",
    "print(p_me)\n",
    "print(l_me)\n",
    "print(p_v_me)\n",
    "print(l_v_me)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 512, 512, 4)\n",
      "(2, 28)\n",
      "(array([[[[0.02352941, 0.14117647, 0.        , 0.70196078],\n",
      "         [0.04313725, 0.08627451, 0.03529412, 0.63137255],\n",
      "         [0.03137255, 0.05490196, 0.        , 0.72941176],\n",
      "         ...,\n",
      "         [0.02745098, 0.1372549 , 0.78431373, 0.1254902 ],\n",
      "         [0.01960784, 0.2       , 0.69019608, 0.15294118],\n",
      "         [0.0627451 , 0.39607843, 0.46666667, 0.14509804]],\n",
      "\n",
      "        [[0.05882353, 0.07843137, 0.00784314, 0.58823529],\n",
      "         [0.0745098 , 0.10980392, 0.01176471, 0.30980392],\n",
      "         [0.1372549 , 0.06666667, 0.        , 0.43529412],\n",
      "         ...,\n",
      "         [0.03137255, 0.08627451, 0.71764706, 0.10980392],\n",
      "         [0.04313725, 0.2745098 , 0.52941176, 0.15294118],\n",
      "         [0.        , 0.15686275, 0.78431373, 0.14117647]],\n",
      "\n",
      "        [[0.09803922, 0.04313725, 0.        , 0.37254902],\n",
      "         [0.09411765, 0.38039216, 0.00784314, 0.4745098 ],\n",
      "         [0.06666667, 0.07058824, 0.00392157, 0.80784314],\n",
      "         ...,\n",
      "         [0.        , 0.09803922, 0.89019608, 0.27843137],\n",
      "         [0.04705882, 0.10196078, 0.87058824, 0.27058824],\n",
      "         [0.03529412, 0.07843137, 0.96470588, 0.25098039]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.01176471, 0.32941176, 0.1254902 , 0.50196078],\n",
      "         [0.00392157, 0.32941176, 0.30196078, 0.35686275],\n",
      "         [0.02352941, 0.39215686, 0.41960784, 0.04313725],\n",
      "         ...,\n",
      "         [0.01568627, 0.05098039, 0.00392157, 0.00784314],\n",
      "         [0.02745098, 0.21960784, 0.00392157, 0.1254902 ],\n",
      "         [0.02352941, 0.11764706, 0.01176471, 0.02352941]],\n",
      "\n",
      "        [[0.05882353, 0.14117647, 0.3254902 , 0.58039216],\n",
      "         [0.05490196, 0.3254902 , 0.41176471, 0.27058824],\n",
      "         [0.04705882, 0.6745098 , 0.4627451 , 0.25490196],\n",
      "         ...,\n",
      "         [0.00392157, 0.09803922, 0.03137255, 0.05098039],\n",
      "         [0.03529412, 0.07058824, 0.        , 0.        ],\n",
      "         [0.03921569, 0.05882353, 0.        , 0.01960784]],\n",
      "\n",
      "        [[0.05098039, 0.62745098, 0.43137255, 0.2745098 ],\n",
      "         [0.03137255, 0.36862745, 0.35294118, 0.16078431],\n",
      "         [0.00392157, 0.61568627, 0.41176471, 0.15294118],\n",
      "         ...,\n",
      "         [0.07058824, 0.00392157, 0.        , 0.01176471],\n",
      "         [0.09411765, 0.03921569, 0.00784314, 0.04705882],\n",
      "         [0.04313725, 0.03529412, 0.        , 0.0627451 ]]],\n",
      "\n",
      "\n",
      "       [[[0.        , 0.        , 0.        , 0.        ],\n",
      "         [0.        , 0.        , 0.        , 0.        ],\n",
      "         [0.        , 0.        , 0.        , 0.        ],\n",
      "         ...,\n",
      "         [0.        , 0.        , 0.        , 0.        ],\n",
      "         [0.00784314, 0.00784314, 0.        , 0.        ],\n",
      "         [0.        , 0.00392157, 0.        , 0.        ]],\n",
      "\n",
      "        [[0.        , 0.        , 0.        , 0.        ],\n",
      "         [0.        , 0.        , 0.        , 0.        ],\n",
      "         [0.        , 0.        , 0.        , 0.        ],\n",
      "         ...,\n",
      "         [0.        , 0.        , 0.        , 0.        ],\n",
      "         [0.        , 0.00392157, 0.        , 0.        ],\n",
      "         [0.01568627, 0.        , 0.        , 0.        ]],\n",
      "\n",
      "        [[0.        , 0.        , 0.        , 0.        ],\n",
      "         [0.        , 0.        , 0.        , 0.        ],\n",
      "         [0.        , 0.        , 0.        , 0.        ],\n",
      "         ...,\n",
      "         [0.03137255, 0.        , 0.        , 0.        ],\n",
      "         [0.        , 0.01176471, 0.        , 0.        ],\n",
      "         [0.        , 0.        , 0.        , 0.        ]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.02352941, 0.54117647, 0.34901961, 0.03529412],\n",
      "         [0.        , 0.39607843, 0.45882353, 0.10588235],\n",
      "         [0.01176471, 0.0627451 , 0.61960784, 0.19607843],\n",
      "         ...,\n",
      "         [0.22745098, 0.01568627, 0.        , 0.05098039],\n",
      "         [0.09411765, 0.05882353, 0.        , 0.01568627],\n",
      "         [0.        , 0.09803922, 0.        , 0.01568627]],\n",
      "\n",
      "        [[0.00784314, 0.7372549 , 0.45098039, 0.03137255],\n",
      "         [0.06666667, 0.57647059, 0.44705882, 0.04313725],\n",
      "         [0.00784314, 0.23137255, 0.68627451, 0.08627451],\n",
      "         ...,\n",
      "         [0.18823529, 0.06666667, 0.        , 0.22352941],\n",
      "         [0.19215686, 0.15686275, 0.        , 0.09411765],\n",
      "         [0.12156863, 0.07058824, 0.        , 0.03529412]],\n",
      "\n",
      "        [[0.00392157, 0.65490196, 0.42745098, 0.05490196],\n",
      "         [0.03137255, 0.45490196, 0.43529412, 0.04705882],\n",
      "         [0.04313725, 0.85490196, 0.2745098 , 0.03529412],\n",
      "         ...,\n",
      "         [0.15686275, 0.13333333, 0.        , 0.24313725],\n",
      "         [0.22745098, 0.05098039, 0.        , 0.11372549],\n",
      "         [0.14509804, 0.05490196, 0.        , 0.04705882]]]]), array([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]]))\n"
     ]
    }
   ],
   "source": [
    "# KAGGLE -----------------------------------\n",
    "tg = ProteinDataGenerator(pathsTrain, labelsTrain, BATCH_SIZE, SHAPE, use_cache=False, augment=False, shuffle=False)\n",
    "vg = ProteinDataGenerator(pathsVal, labelsVal, BATCH_SIZE, SHAPE, use_cache=False, shuffle=False)\n",
    "print (tg[1][0].shape)\n",
    "print (tg[1][1].shape)\n",
    "print (tg[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 512, 512, 4)\n",
      "(2, 28)\n",
      "(array([[[[0.        , 0.        , 0.        , 0.        ],\n",
      "         [0.        , 0.        , 0.        , 0.        ],\n",
      "         [0.        , 0.        , 0.        , 0.        ],\n",
      "         ...,\n",
      "         [0.04313725, 0.1254902 , 0.01568627, 0.07058824],\n",
      "         [0.04705882, 0.2       , 0.16862745, 0.05490196],\n",
      "         [0.        , 0.05882353, 0.37254902, 0.00784314]],\n",
      "\n",
      "        [[0.        , 0.        , 0.        , 0.        ],\n",
      "         [0.        , 0.        , 0.        , 0.        ],\n",
      "         [0.        , 0.        , 0.        , 0.        ],\n",
      "         ...,\n",
      "         [0.02352941, 0.14901961, 0.07058824, 0.06666667],\n",
      "         [0.16470588, 0.31764706, 0.25098039, 0.02352941],\n",
      "         [0.05098039, 0.18823529, 0.31764706, 0.00784314]],\n",
      "\n",
      "        [[0.        , 0.        , 0.        , 0.        ],\n",
      "         [0.        , 0.        , 0.        , 0.        ],\n",
      "         [0.        , 0.        , 0.        , 0.        ],\n",
      "         ...,\n",
      "         [0.10980392, 0.14901961, 0.0627451 , 0.05882353],\n",
      "         [0.01568627, 0.22352941, 0.28627451, 0.05882353],\n",
      "         [0.00784314, 0.1254902 , 0.35294118, 0.00392157]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.        , 0.        , 0.        , 0.        ],\n",
      "         [0.        , 0.        , 0.        , 0.        ],\n",
      "         [0.        , 0.        , 0.        , 0.        ],\n",
      "         ...,\n",
      "         [0.        , 0.        , 0.        , 0.        ],\n",
      "         [0.        , 0.        , 0.        , 0.        ],\n",
      "         [0.        , 0.        , 0.        , 0.        ]],\n",
      "\n",
      "        [[0.        , 0.        , 0.        , 0.        ],\n",
      "         [0.        , 0.        , 0.        , 0.        ],\n",
      "         [0.        , 0.        , 0.        , 0.        ],\n",
      "         ...,\n",
      "         [0.        , 0.        , 0.        , 0.        ],\n",
      "         [0.        , 0.        , 0.        , 0.        ],\n",
      "         [0.        , 0.        , 0.        , 0.        ]],\n",
      "\n",
      "        [[0.        , 0.        , 0.        , 0.        ],\n",
      "         [0.        , 0.        , 0.        , 0.        ],\n",
      "         [0.        , 0.        , 0.        , 0.        ],\n",
      "         ...,\n",
      "         [0.        , 0.        , 0.        , 0.        ],\n",
      "         [0.        , 0.        , 0.        , 0.        ],\n",
      "         [0.        , 0.        , 0.        , 0.        ]]],\n",
      "\n",
      "\n",
      "       [[[0.02352941, 0.14117647, 0.        , 0.70196078],\n",
      "         [0.04313725, 0.08627451, 0.03529412, 0.63137255],\n",
      "         [0.03137255, 0.05490196, 0.        , 0.72941176],\n",
      "         ...,\n",
      "         [0.02745098, 0.1372549 , 0.78431373, 0.1254902 ],\n",
      "         [0.01960784, 0.2       , 0.69019608, 0.15294118],\n",
      "         [0.0627451 , 0.39607843, 0.46666667, 0.14509804]],\n",
      "\n",
      "        [[0.05882353, 0.07843137, 0.00784314, 0.58823529],\n",
      "         [0.0745098 , 0.10980392, 0.01176471, 0.30980392],\n",
      "         [0.1372549 , 0.06666667, 0.        , 0.43529412],\n",
      "         ...,\n",
      "         [0.03137255, 0.08627451, 0.71764706, 0.10980392],\n",
      "         [0.04313725, 0.2745098 , 0.52941176, 0.15294118],\n",
      "         [0.        , 0.15686275, 0.78431373, 0.14117647]],\n",
      "\n",
      "        [[0.09803922, 0.04313725, 0.        , 0.37254902],\n",
      "         [0.09411765, 0.38039216, 0.00784314, 0.4745098 ],\n",
      "         [0.06666667, 0.07058824, 0.00392157, 0.80784314],\n",
      "         ...,\n",
      "         [0.        , 0.09803922, 0.89019608, 0.27843137],\n",
      "         [0.04705882, 0.10196078, 0.87058824, 0.27058824],\n",
      "         [0.03529412, 0.07843137, 0.96470588, 0.25098039]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.01176471, 0.32941176, 0.1254902 , 0.50196078],\n",
      "         [0.00392157, 0.32941176, 0.30196078, 0.35686275],\n",
      "         [0.02352941, 0.39215686, 0.41960784, 0.04313725],\n",
      "         ...,\n",
      "         [0.01568627, 0.05098039, 0.00392157, 0.00784314],\n",
      "         [0.02745098, 0.21960784, 0.00392157, 0.1254902 ],\n",
      "         [0.02352941, 0.11764706, 0.01176471, 0.02352941]],\n",
      "\n",
      "        [[0.05882353, 0.14117647, 0.3254902 , 0.58039216],\n",
      "         [0.05490196, 0.3254902 , 0.41176471, 0.27058824],\n",
      "         [0.04705882, 0.6745098 , 0.4627451 , 0.25490196],\n",
      "         ...,\n",
      "         [0.00392157, 0.09803922, 0.03137255, 0.05098039],\n",
      "         [0.03529412, 0.07058824, 0.        , 0.        ],\n",
      "         [0.03921569, 0.05882353, 0.        , 0.01960784]],\n",
      "\n",
      "        [[0.05098039, 0.62745098, 0.43137255, 0.2745098 ],\n",
      "         [0.03137255, 0.36862745, 0.35294118, 0.16078431],\n",
      "         [0.00392157, 0.61568627, 0.41176471, 0.15294118],\n",
      "         ...,\n",
      "         [0.07058824, 0.00392157, 0.        , 0.01176471],\n",
      "         [0.09411765, 0.03921569, 0.00784314, 0.04705882],\n",
      "         [0.04313725, 0.03529412, 0.        , 0.0627451 ]]]]), array([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]))\n"
     ]
    }
   ],
   "source": [
    "# MINE -----------------------------------\n",
    "class MyArgs:\n",
    "    train_folder = TRAIN_PATH\n",
    "    batch_size = BATCH_SIZE\n",
    "    validation_steps = 3\n",
    "    \n",
    "args = MyArgs()\n",
    "training_generator = hprotein.HproteinDataGenerator(args, args.train_folder, p_me, l_me, augment=True)\n",
    "validate_generator = hprotein.HproteinDataGenerator(args, args.train_folder, p_v_me, l_v_me, augment=False)\n",
    "print (training_generator[0][0].shape)\n",
    "print (training_generator[0][1].shape)\n",
    "print (training_generator[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9473683\n"
     ]
    }
   ],
   "source": [
    "# KAGGLE -----------------------------------\n",
    "def f1(y_true, y_pred):\n",
    "    #y_pred = K.round(y_pred)\n",
    "    #y_pred = K.cast(K.greater(K.clip(y_pred, 0, 1), THRESHOLD), K.floatx())\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return K.mean(f1)\n",
    "\n",
    "# unit test\n",
    "y_true = K.variable(np.ones(10, np.uint8))\n",
    "y_pred = np.ones(10, np.uint8)\n",
    "y_pred[0] = 0\n",
    "y_pred = K.variable(y_pred)\n",
    "\n",
    "ftest = f1(y_true, y_pred)\n",
    "#ftest = tf.constant(5)\n",
    "\n",
    "init_op = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init_op)\n",
    "print (sess.run(ftest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9473683\n"
     ]
    }
   ],
   "source": [
    "# MINE -----------------------------------\n",
    "y_true = K.variable(np.ones(10, np.uint8))\n",
    "y_pred = np.ones(10, np.uint8)\n",
    "y_pred[0] = 0\n",
    "y_pred = K.variable(y_pred)\n",
    "\n",
    "my_ftest = hprotein.f1(y_true, y_pred)\n",
    "init_op = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init_op)\n",
    "print (sess.run(my_ftest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.052631676\n"
     ]
    }
   ],
   "source": [
    "# KAGGLE -----------------------------------\n",
    "def f1_loss(y_true, y_pred):\n",
    "    \n",
    "    #y_pred = K.cast(K.greater(K.clip(y_pred, 0, 1), THRESHOLD), K.floatx())\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return 1-K.mean(f1)\n",
    "\n",
    "# unit test\n",
    "y_true = K.variable(np.ones(10, np.uint8))\n",
    "y_pred = np.ones(10, np.uint8)\n",
    "y_pred[0] = 0\n",
    "y_pred = K.variable(y_pred)\n",
    "\n",
    "ftest = f1_loss(y_true, y_pred)\n",
    "#ftest = tf.constant(5)\n",
    "\n",
    "init_op = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init_op)\n",
    "print (sess.run(ftest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.052631676\n"
     ]
    }
   ],
   "source": [
    "# MINE -----------------------------------\n",
    "y_true = K.variable(np.ones(10, np.uint8))\n",
    "y_pred = np.ones(10, np.uint8)\n",
    "y_pred[0] = 0\n",
    "y_pred = K.variable(y_pred)\n",
    "\n",
    "my_ftest = hprotein.f1_loss(y_true, y_pred)\n",
    "#ftest = tf.constant(5)\n",
    "\n",
    "init_op = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init_op)\n",
    "print (sess.run(my_ftest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 512, 512, 4)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 512, 512, 4)  16          input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 510, 510, 32) 1184        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_1 (ReLU)                  (None, 510, 510, 32) 0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 510, 510, 32) 128         re_lu_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 255, 255, 32) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 255, 255, 32) 0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 255, 255, 32) 128         dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 127, 127, 64) 18496       batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_2 (ReLU)                  (None, 127, 127, 64) 0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 127, 127, 64) 256         re_lu_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 125, 125, 64) 36928       batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_3 (ReLU)                  (None, 125, 125, 64) 0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 125, 125, 64) 256         re_lu_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 123, 123, 64) 36928       batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_4 (ReLU)                  (None, 123, 123, 64) 0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 123, 123, 64) 256         re_lu_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 61, 61, 64)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 61, 61, 64)   0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 61, 61, 64)   256         dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 59, 59, 128)  73856       batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_5 (ReLU)                  (None, 59, 59, 128)  0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 59, 59, 128)  512         re_lu_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 57, 57, 128)  147584      batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_6 (ReLU)                  (None, 57, 57, 128)  0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 57, 57, 128)  512         re_lu_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 55, 55, 128)  147584      batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_7 (ReLU)                  (None, 55, 55, 128)  0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 55, 55, 128)  0           re_lu_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 32)           0           dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_2 (Glo (None, 64)           0           dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_3 (Glo (None, 128)          0           dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 224)          0           global_average_pooling2d_1[0][0] \n",
      "                                                                 global_average_pooling2d_2[0][0] \n",
      "                                                                 global_average_pooling2d_3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 224)          896         concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          57600       batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 256)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 256)          1024        dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 256)          65792       batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 256)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 28)           7196        dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 28)           0           dense_3[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 597,388\n",
      "Trainable params: 595,268\n",
      "Non-trainable params: 2,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# KAGGLE -----------------------------------\n",
    "def create_model(input_shape):\n",
    "    \n",
    "    dropRate = 0.25\n",
    "    \n",
    "    init = Input(input_shape)\n",
    "    x = BatchNormalization(axis=-1)(init)\n",
    "    x = Conv2D(32, (3, 3))(x) #, strides=(2,2))(x)\n",
    "    x = ReLU()(x)\n",
    "\n",
    "    x = BatchNormalization(axis=-1)(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    ginp1 = Dropout(dropRate)(x)\n",
    "    \n",
    "    x = BatchNormalization(axis=-1)(ginp1)\n",
    "    x = Conv2D(64, (3, 3), strides=(2,2))(x)\n",
    "    x = ReLU()(x)\n",
    "    x = BatchNormalization(axis=-1)(x)\n",
    "    x = Conv2D(64, (3, 3))(x)\n",
    "    x = ReLU()(x)\n",
    "    x = BatchNormalization(axis=-1)(x)\n",
    "    x = Conv2D(64, (3, 3))(x)\n",
    "    x = ReLU()(x)\n",
    "    \n",
    "    x = BatchNormalization(axis=-1)(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    ginp2 = Dropout(dropRate)(x)\n",
    "    \n",
    "    x = BatchNormalization(axis=-1)(ginp2)\n",
    "    x = Conv2D(128, (3, 3))(x)\n",
    "    x = ReLU()(x)\n",
    "    x = BatchNormalization(axis=-1)(x)\n",
    "    x = Conv2D(128, (3, 3))(x)\n",
    "    x = ReLU()(x)\n",
    "    x = BatchNormalization(axis=-1)(x)\n",
    "    x = Conv2D(128, (3, 3))(x)\n",
    "    x = ReLU()(x)\n",
    "    ginp3 = Dropout(dropRate)(x)\n",
    "    \n",
    "    gap1 = GlobalAveragePooling2D()(ginp1)\n",
    "    gap2 = GlobalAveragePooling2D()(ginp2)\n",
    "    gap3 = GlobalAveragePooling2D()(ginp3)\n",
    "    \n",
    "    x = Concatenate()([gap1, gap2, gap3])\n",
    "    \n",
    "    x = BatchNormalization(axis=-1)(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(dropRate)(x)\n",
    "    \n",
    "    x = BatchNormalization(axis=-1)(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    \n",
    "    x = Dense(28)(x)\n",
    "    x = Activation('sigmoid')(x)\n",
    "    \n",
    "    model = Model(init, x)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# unit\n",
    "model = create_model(SHAPE)\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer=Adam(1e-03),\n",
    "    metrics=['acc',hprotein.f1])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 512, 512, 4)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 512, 512, 4)  16          input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 510, 510, 32) 1184        batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_8 (ReLU)                  (None, 510, 510, 32) 0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 510, 510, 32) 128         re_lu_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 255, 255, 32) 0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 255, 255, 32) 0           max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 255, 255, 32) 128         dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 127, 127, 64) 18496       batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_9 (ReLU)                  (None, 127, 127, 64) 0           conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 127, 127, 64) 256         re_lu_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 125, 125, 64) 36928       batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_10 (ReLU)                 (None, 125, 125, 64) 0           conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 125, 125, 64) 256         re_lu_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 123, 123, 64) 36928       batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_11 (ReLU)                 (None, 123, 123, 64) 0           conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 123, 123, 64) 256         re_lu_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 61, 61, 64)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 61, 61, 64)   0           max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 61, 61, 64)   256         dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 59, 59, 128)  73856       batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_12 (ReLU)                 (None, 59, 59, 128)  0           conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 59, 59, 128)  512         re_lu_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 57, 57, 128)  147584      batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_13 (ReLU)                 (None, 57, 57, 128)  0           conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 57, 57, 128)  512         re_lu_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 55, 55, 128)  147584      batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_14 (ReLU)                 (None, 55, 55, 128)  0           conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 55, 55, 128)  0           re_lu_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_4 (Glo (None, 32)           0           dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_5 (Glo (None, 64)           0           dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_6 (Glo (None, 128)          0           dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 224)          0           global_average_pooling2d_4[0][0] \n",
      "                                                                 global_average_pooling2d_5[0][0] \n",
      "                                                                 global_average_pooling2d_6[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 224)          896         concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 256)          57600       batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 256)          0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 256)          1024        dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 256)          65792       batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 256)          0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 28)           7196        dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 28)           0           dense_6[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 597,388\n",
      "Trainable params: 595,268\n",
      "Non-trainable params: 2,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# MINE -----------------------------------\n",
    "my_model = hprotein.create_model(model_name='gap_net_bn_relu')\n",
    "my_model.compile(loss='binary_crossentropy', optimizer=Adam(1e-03), metrics=['acc', hprotein.f1])\n",
    "my_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KAGGLE -----------------------------------\n",
    "checkpoint = ModelCheckpoint('./base.model', monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='min', period=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MINE -----------------------------------\n",
    "my_checkpoint = ModelCheckpoint('{}.model'.format('model_12345'),\n",
    "                                 monitor='val_loss', verbose=1, save_best_only=True,\n",
    "                                 save_weights_only=False, mode='min', period=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "4/4 [==============================] - 23s 6s/step - loss: 0.7091 - acc: 0.6714 - f1: 0.0488 - val_loss: 2.5108 - val_acc: 0.7262 - val_f1: 0.0439\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.51078, saving model to ./base.model\n",
      "Epoch 2/5\n",
      "4/4 [==============================] - 17s 4s/step - loss: 0.6130 - acc: 0.7449 - f1: 0.0478 - val_loss: 1.2949 - val_acc: 0.7262 - val_f1: 0.0404\n",
      "\n",
      "Epoch 00002: val_loss improved from 2.51078 to 1.29493, saving model to ./base.model\n",
      "Epoch 3/5\n",
      "4/4 [==============================] - 18s 4s/step - loss: 0.4909 - acc: 0.8459 - f1: 0.0575 - val_loss: 0.7066 - val_acc: 0.7500 - val_f1: 0.0238\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.29493 to 0.70663, saving model to ./base.model\n",
      "Epoch 4/5\n",
      "4/4 [==============================] - 17s 4s/step - loss: 0.4214 - acc: 0.8964 - f1: 0.0538 - val_loss: 0.4023 - val_acc: 0.8690 - val_f1: 0.0132\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.70663 to 0.40227, saving model to ./base.model\n",
      "Epoch 5/5\n",
      "4/4 [==============================] - 20s 5s/step - loss: 0.3344 - acc: 0.9469 - f1: 0.0576 - val_loss: 0.3649 - val_acc: 0.8690 - val_f1: 0.0095\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.40227 to 0.36485, saving model to ./base.model\n"
     ]
    }
   ],
   "source": [
    "# KAGGLE -----------------------------------\n",
    "epochs = 5\n",
    "\n",
    "use_multiprocessing = False # DO NOT COMBINE MULTIPROCESSING WITH CACHE! \n",
    "workers = 1 # DO NOT COMBINE MULTIPROCESSING WITH CACHE! \n",
    "\n",
    "hist = model.fit_generator(\n",
    "    tg,\n",
    "    steps_per_epoch=len(tg),\n",
    "    validation_data=vg,\n",
    "    validation_steps=8,\n",
    "    epochs=epochs,\n",
    "    use_multiprocessing=use_multiprocessing,\n",
    "    workers=workers,\n",
    "    verbose=1,\n",
    "    callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "4/4 [==============================] - 20s 5s/step - loss: 0.6921 - acc: 0.6531 - f1: 0.0639 - val_loss: 3.7729 - val_acc: 0.5952 - val_f1: 0.0126\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 3.77287, saving model to model_12345.model\n",
      "Epoch 2/5\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.6091 - acc: 0.7495 - f1: 0.0557 - val_loss: 1.6211 - val_acc: 0.7143 - val_f1: 0.0231\n",
      "\n",
      "Epoch 00002: val_loss improved from 3.77287 to 1.62110, saving model to model_12345.model\n",
      "Epoch 3/5\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.5387 - acc: 0.8184 - f1: 0.0573 - val_loss: 1.1879 - val_acc: 0.7500 - val_f1: 0.0112\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.62110 to 1.18793, saving model to model_12345.model\n",
      "Epoch 4/5\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.4430 - acc: 0.9138 - f1: 0.0563 - val_loss: 0.9279 - val_acc: 0.8452 - val_f1: 0.0139\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.18793 to 0.92794, saving model to model_12345.model\n",
      "Epoch 5/5\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.3814 - acc: 0.9240 - f1: 0.0625 - val_loss: 0.8000 - val_acc: 0.9048 - val_f1: 0.0206\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.92794 to 0.80003, saving model to model_12345.model\n"
     ]
    }
   ],
   "source": [
    "# MINE -----------------------------------\n",
    "my_hist = my_model.fit_generator(training_generator,\n",
    "                               steps_per_epoch=len(training_generator),\n",
    "                               validation_data=validate_generator,\n",
    "                               validation_steps=8,\n",
    "                               epochs=5,\n",
    "                               use_multiprocessing=False,\n",
    "#                               max_queue_size=128,\n",
    "                               workers=1,\n",
    "                               verbose=1,\n",
    "                               callbacks=[my_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "4/4 [==============================] - 17s 4s/step - loss: 0.3630 - acc: 0.9378 - f1: 0.0387 - val_loss: 0.4302 - val_acc: 0.9286 - val_f1: 0.0036\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.43018, saving model to ./my_base.model\n",
      "Epoch 2/5\n",
      "4/4 [==============================] - 22s 6s/step - loss: 0.3143 - acc: 0.9332 - f1: 0.0482 - val_loss: 0.4425 - val_acc: 0.9405 - val_f1: 0.0022\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.43018\n",
      "Epoch 3/5\n",
      "4/4 [==============================] - 19s 5s/step - loss: 0.2726 - acc: 0.9378 - f1: 0.0459 - val_loss: 0.4440 - val_acc: 0.9286 - val_f1: 0.0047\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.43018\n",
      "Epoch 4/5\n",
      "4/4 [==============================] - 18s 4s/step - loss: 0.2448 - acc: 0.9515 - f1: 0.0515 - val_loss: 0.4939 - val_acc: 0.9286 - val_f1: 0.0033\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.43018\n",
      "Epoch 5/5\n",
      "4/4 [==============================] - 22s 5s/step - loss: 0.2467 - acc: 0.9469 - f1: 0.0445 - val_loss: 0.5004 - val_acc: 0.9286 - val_f1: 0.0030\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.43018\n"
     ]
    }
   ],
   "source": [
    "# MY DATA GENERATORS WITH KAGGLE MODEL -----------------------------------\n",
    "checkpoint = ModelCheckpoint('./my_base.model', monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='min', period=1)\n",
    "\n",
    "epochs = 5\n",
    "\n",
    "use_multiprocessing = False # DO NOT COMBINE MULTIPROCESSING WITH CACHE! \n",
    "workers = 1 # DO NOT COMBINE MULTIPROCESSING WITH CACHE! \n",
    "\n",
    "hist = model.fit_generator(\n",
    "    training_generator,\n",
    "    steps_per_epoch=len(training_generator),\n",
    "    validation_data=validate_generator,\n",
    "    validation_steps=8,\n",
    "    epochs=epochs,\n",
    "    use_multiprocessing=use_multiprocessing,\n",
    "    workers=workers,\n",
    "    verbose=1,\n",
    "    callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 2/2 [00:02<00:00,  1.16s/it]\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]/Users/farrar/py3.6.5/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "  1%|          | 6/1000 [00:00<00:16, 59.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 28) (3, 28)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 15/1000 [00:00<00:13, 70.61it/s]/Users/farrar/py3.6.5/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "100%|| 1000/1000 [00:09<00:00, 106.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8 0.  0.5 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.5 0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  1.  0.  0. ]\n",
      "0.09999999999999999\n",
      "[0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.001 0.    0.   ]\n",
      "thresholds -> [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.001 0.    0.   ]\n",
      "f1 macro   -> 0.09999999999999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# KAGGLE -----------------------------------\n",
    "from sklearn.metrics import f1_score as off1\n",
    "\n",
    "def getOptimalT(mdl, fullValGen):\n",
    "    lastFullValPred = np.empty((0, 28))\n",
    "    lastFullValLabels = np.empty((0, 28))\n",
    "    for i in tqdm(range(len(fullValGen))):\n",
    "        im, lbl = fullValGen[i]\n",
    "        scores = mdl.predict(im)\n",
    "        lastFullValPred = np.append(lastFullValPred, scores, axis=0)\n",
    "        lastFullValLabels = np.append(lastFullValLabels, lbl, axis=0)\n",
    "    print(lastFullValPred.shape, lastFullValLabels.shape)\n",
    "\n",
    "    rng = np.arange(0, 1, 0.001)\n",
    "    f1s = np.zeros((rng.shape[0], 28))\n",
    "    for j, t in enumerate(tqdm(rng)):\n",
    "        for i in range(28):\n",
    "            p = np.array(lastFullValPred[:, i] > t, dtype=np.int8)\n",
    "            # scoref1 = K.eval(f1_score(fullValLabels[:,i], p, average='binary'))\n",
    "            scoref1 = off1(lastFullValLabels[:, i], p, average='binary')\n",
    "            f1s[j, i] = scoref1\n",
    "\n",
    "    print(np.max(f1s, axis=0))\n",
    "    print(np.mean(np.max(f1s, axis=0)))\n",
    "\n",
    "    T = np.empty(28)\n",
    "    for i in range(28):\n",
    "        T[i] = rng[np.where(f1s[:, i] == np.max(f1s[:, i]))[0][0]]\n",
    "    # print('Choosing threshold: ', T, ', validation F1-score: ', max(f1s))\n",
    "    print(T)\n",
    "\n",
    "    return T, np.mean(np.max(f1s, axis=0))\n",
    "\n",
    "# unit test \n",
    "thresholds, f1_macro = getOptimalT(model, vg)\n",
    "print('thresholds -> {}'.format(thresholds))\n",
    "print('f1 macro   -> {}'.format(f1_macro))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 2/2 [00:01<00:00,  1.08it/s]\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]/Users/farrar/py3.6.5/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "  0%|          | 5/1000 [00:00<00:20, 47.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 28) (3, 28)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|         | 13/1000 [00:00<00:15, 62.41it/s]/Users/farrar/py3.6.5/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "100%|| 1000/1000 [00:09<00:00, 102.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8 0.  0.5 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.5 0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  1.  0.  0. ]\n",
      "0.09999999999999999\n",
      "[0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.001 0.    0.   ]\n",
      "thresholds -> [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.001 0.    0.   ]\n",
      "f1 macro   -> 0.09999999999999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# MINE ----------------------------------------\n",
    "my_thresholds, my_f1_macro = hprotein.get_max_fscore_matrix(model, vg)\n",
    "print('thresholds -> {}'.format(my_thresholds))\n",
    "print('f1 macro   -> {}'.format(my_f1_macro))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "['../stage1_test/00cfafb0-bacb-11e8-b2b8-ac1f6b6435d0'\n",
      " '../stage1_test/00d2a4f8-bad6-11e8-b2b9-ac1f6b6435d0'\n",
      " '../stage1_test/000cce7e-bad4-11e8-b2b8-ac1f6b6435d0'\n",
      " '../stage1_test/0006faa6-bac7-11e8-b2b7-ac1f6b6435d0'\n",
      " '../stage1_test/0008baca-bad7-11e8-b2b9-ac1f6b6435d0'\n",
      " '../stage1_test/003170fa-bacd-11e8-b2b8-ac1f6b6435d0'\n",
      " '../stage1_test/0031820a-baca-11e8-b2b8-ac1f6b6435d0']\n",
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 4/4 [00:06<00:00,  1.70s/it]\n"
     ]
    }
   ],
   "source": [
    "# Kaggle Predict\n",
    "bestModel = load_model('../models/model_ca200f_fine_tune.model', custom_objects={'f1': f1, 'f1_loss': f1_loss})\n",
    "p_test, l_test = getTestDataset()\n",
    "T = np.load('../models/model_ca200f_fine_tune_thresh.npy')\n",
    "\n",
    "print (len(p_test))\n",
    "print (p_test)\n",
    "print (len(l_test))\n",
    "#print (l_test)\n",
    "\n",
    "pathsTest = p_test\n",
    "labelsTest = l_test\n",
    "\n",
    "testg = ProteinDataGenerator(pathsTest, labelsTest, BATCH_SIZE, SHAPE)\n",
    "submit = pd.read_csv('../stage1_submit/sample_submission_short.csv')\n",
    "P = np.zeros((pathsTest.shape[0], 28))\n",
    "for i in tqdm(range(len(testg))):\n",
    "    images, labels = testg[i]\n",
    "    score = bestModel.predict(images)\n",
    "    P[i*BATCH_SIZE:i*BATCH_SIZE+score.shape[0]] = score\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.82032180e-01 1.40867790e-03 1.59820469e-04 3.66725399e-05\n",
      "  2.44520546e-04 1.47103448e-04 2.30542361e-03 6.95718278e-04\n",
      "  1.42989132e-09 1.07559572e-10 5.93328013e-14 1.27453264e-03\n",
      "  2.43581948e-03 9.18872713e-04 6.16045290e-05 2.26510029e-08\n",
      "  6.74355924e-02 4.51296847e-03 6.87073451e-04 3.49327992e-03\n",
      "  3.46455025e-04 4.57480289e-02 3.75627391e-02 9.83743276e-03\n",
      "  1.44700723e-04 5.21763265e-01 5.57976365e-02 5.11006419e-07]\n",
      " [2.72339303e-02 7.36814982e-05 2.09475635e-03 1.62891322e-03\n",
      "  1.75289810e-03 9.63745639e-04 2.97165900e-01 9.88106243e-04\n",
      "  7.56508598e-07 1.28239259e-08 4.73354212e-12 5.78880534e-02\n",
      "  9.59956460e-03 1.19251767e-02 1.22812926e-04 1.33004996e-09\n",
      "  1.10593741e-03 3.89207526e-05 3.17532074e-04 1.17047317e-03\n",
      "  1.13920483e-04 1.03853576e-01 4.70100455e-02 4.08556223e-01\n",
      "  2.07659741e-06 3.12625378e-01 4.78453608e-03 2.51691432e-07]\n",
      " [1.50032789e-01 3.78631894e-03 2.32310733e-03 5.73038764e-04\n",
      "  4.61017853e-03 2.41895374e-02 3.79693210e-02 4.13314670e-01\n",
      "  3.70801892e-04 1.03534649e-05 5.73903117e-06 1.12986052e-02\n",
      "  2.63659470e-03 6.49740628e-04 1.72941800e-05 7.17531423e-10\n",
      "  1.19910226e-03 2.08977712e-04 9.88189876e-03 1.51611697e-02\n",
      "  1.11675002e-02 3.33854067e-03 1.99956456e-04 2.32710898e-01\n",
      "  3.07677663e-04 1.80981725e-01 1.58643187e-03 3.91316416e-06]\n",
      " [7.26949871e-01 6.92013600e-06 5.98688530e-05 1.82965960e-05\n",
      "  8.62997305e-03 7.15798140e-01 7.36616040e-03 2.49200937e-04\n",
      "  4.44278427e-08 2.27110908e-12 6.87953980e-13 1.08054606e-04\n",
      "  2.00461568e-06 7.50668696e-04 9.81223769e-04 2.68304545e-10\n",
      "  1.63097028e-03 3.05413778e-05 3.40594910e-04 1.70681886e-02\n",
      "  3.59589336e-08 1.53061822e-02 1.01744790e-05 3.29262912e-05\n",
      "  3.79959317e-08 9.41043139e-01 3.30073613e-06 4.17117556e-11]\n",
      " [9.96184051e-01 6.50595222e-03 1.69999152e-03 7.31227687e-04\n",
      "  1.03436771e-03 2.47167423e-03 2.19933660e-04 1.59793068e-03\n",
      "  4.92793417e-10 1.21429993e-12 1.26128616e-15 1.43600930e-03\n",
      "  2.19648052e-03 3.61893181e-04 1.42814548e-04 1.18137985e-04\n",
      "  2.87596546e-02 1.19661931e-02 1.48913590e-03 2.24145129e-03\n",
      "  3.24421198e-05 2.77580209e-02 1.01728144e-03 1.08823506e-03\n",
      "  9.17415018e-05 2.69379616e-01 4.72374447e-03 8.79036179e-07]\n",
      " [7.69172013e-02 1.31679335e-05 9.78068054e-01 1.89932417e-02\n",
      "  2.42592956e-04 5.27362048e-04 3.95037374e-03 8.79950356e-04\n",
      "  2.91226976e-09 1.39265907e-15 6.55025600e-17 1.30582554e-03\n",
      "  4.50916559e-06 5.98363749e-06 3.64834086e-05 5.98577587e-09\n",
      "  1.43961236e-03 8.71404912e-03 2.40832521e-03 2.05748875e-04\n",
      "  2.81995627e-09 1.34544196e-02 1.86135949e-05 3.84018349e-04\n",
      "  5.19527035e-08 9.54538465e-01 6.20250012e-06 1.29965691e-11]\n",
      " [5.49290190e-03 2.31144717e-03 2.31991464e-04 2.57109146e-04\n",
      "  2.12595938e-03 5.48095861e-03 2.44503599e-02 3.44892621e-01\n",
      "  4.68677463e-05 1.52886041e-05 2.26561178e-06 1.20166473e-01\n",
      "  4.63307893e-04 4.37422801e-04 4.27798321e-03 6.61285748e-10\n",
      "  4.48622145e-02 2.81131733e-03 3.79285850e-02 7.84619227e-02\n",
      "  2.17562332e-03 3.55491793e-04 1.44235106e-04 3.09580797e-03\n",
      "  1.59384515e-02 6.28292933e-02 2.05127941e-03 5.63097551e-08]]\n"
     ]
    }
   ],
   "source": [
    "print(P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 7/7 [00:00<00:00, 5158.14it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00cfafb0-bacb-11e8-b2b8-ac1f6b6435d0</td>\n",
       "      <td>0 25 27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00d2a4f8-bad6-11e8-b2b9-ac1f6b6435d0</td>\n",
       "      <td>23 25 27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000cce7e-bad4-11e8-b2b8-ac1f6b6435d0</td>\n",
       "      <td>7 27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0006faa6-bac7-11e8-b2b7-ac1f6b6435d0</td>\n",
       "      <td>0 5 25 27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0008baca-bad7-11e8-b2b9-ac1f6b6435d0</td>\n",
       "      <td>0 27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>003170fa-bacd-11e8-b2b8-ac1f6b6435d0</td>\n",
       "      <td>2 25 27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0031820a-baca-11e8-b2b8-ac1f6b6435d0</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Id  Predicted\n",
       "0  00cfafb0-bacb-11e8-b2b8-ac1f6b6435d0    0 25 27\n",
       "1  00d2a4f8-bad6-11e8-b2b9-ac1f6b6435d0   23 25 27\n",
       "2  000cce7e-bad4-11e8-b2b8-ac1f6b6435d0       7 27\n",
       "3  0006faa6-bac7-11e8-b2b7-ac1f6b6435d0  0 5 25 27\n",
       "4  0008baca-bad7-11e8-b2b9-ac1f6b6435d0       0 27\n",
       "5  003170fa-bacd-11e8-b2b8-ac1f6b6435d0    2 25 27\n",
       "6  0031820a-baca-11e8-b2b8-ac1f6b6435d0         27"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PP = np.array(P)\n",
    "prediction = []\n",
    "\n",
    "for row in tqdm(range(submit.shape[0])):\n",
    "\n",
    "    str_label = ''\n",
    "\n",
    "    for col in range(PP.shape[1]):\n",
    "        if (PP[row, col] < T[col]):\n",
    "            str_label += ''\n",
    "        else:\n",
    "            str_label += str(col) + ' '\n",
    "    prediction.append(str_label.strip())\n",
    "\n",
    "submit['Predicted'] = np.array(prediction)\n",
    "submit.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "def get_best_model(args):\n",
    "\n",
    "    final_model = None\n",
    "    max_thresholds_matrix = None\n",
    "\n",
    "    # Get thresholds\n",
    "    logging.info('Getting correct model and thresholds...')\n",
    "    if os.path.isfile('../models/{}_thresh.npy'.format(args.model_label)):\n",
    "\n",
    "        # load model\n",
    "        logging.info('Loading model {}...'.format(args.model_label))\n",
    "        final_model = load_model('../models/{}.model'.format(args.model_label), custom_objects={'f1': f1})\n",
    "\n",
    "        # load thresholds\n",
    "        max_thresholds_matrix = np.load('../models/{}_thresh.npy'.format(args.model_label))\n",
    "\n",
    "    elif os.path.isfile('../models/{}_fine_tune_thresh.npy'.format(args.model_label)):\n",
    "\n",
    "        # load model\n",
    "        logging.info('Loading model {}_fine_tune...'.format(args.model_label))\n",
    "        final_model = load_model('../models/{}_fine_tune.model'.format(args.model_label),\n",
    "                                 custom_objects={'f1': f1, 'f1_loss': f1_loss})\n",
    "\n",
    "        # load thresholds\n",
    "        max_thresholds_matrix = np.load('../models/{}_fine_tune_thresh.npy'.format(args.model_label))\n",
    "    else:\n",
    "        logging.warning(\"Can't find model file models/{}.model or models/{}_fine_tune.model\".format(args.model_label,\n",
    "                                                                                                    args.model_label))\n",
    "\n",
    "    if max_thresholds_matrix is not None:\n",
    "        logging.info('Using the following thresholds:')\n",
    "        logging.info(max_thresholds_matrix)\n",
    "\n",
    "    return final_model, max_thresholds_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyArgs:\n",
    "    train_folder = TRAIN_PATH\n",
    "    batch_size = BATCH_SIZE\n",
    "    validation_steps = 3\n",
    "    submission_folder = '../stage1_submit'\n",
    "    predict_folder = '../stage1_test'\n",
    "    model_label = 'model_ca200f'\n",
    "    model_name = 'gap_net_bn_relu'\n",
    "    \n",
    "args = MyArgs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting run_predict...\n",
      "Reading predict test set from ../stage1_test...\n",
      "['0008baca-bad7-11e8-b2b9-ac1f6b6435d0'\n",
      " '00cfafb0-bacb-11e8-b2b8-ac1f6b6435d0'\n",
      " '000cce7e-bad4-11e8-b2b8-ac1f6b6435d0'\n",
      " '0006faa6-bac7-11e8-b2b7-ac1f6b6435d0'\n",
      " '0031820a-baca-11e8-b2b8-ac1f6b6435d0'\n",
      " '00d2a4f8-bad6-11e8-b2b9-ac1f6b6435d0'\n",
      " '003170fa-bacd-11e8-b2b8-ac1f6b6435d0']\n",
      "Starting prediction run...\n",
      "Predicting batch 0 of 4\n"
     ]
    }
   ],
   "source": [
    "# Log start of predict process\n",
    "print('Starting run_predict...')\n",
    "\n",
    "# get the best model and related threshold matrix\n",
    "final_model, max_thresholds_matrix = get_best_model(args)\n",
    "\n",
    "# get predict data\n",
    "print('Reading predict test set from {}...'.format(args.predict_folder))\n",
    "predict_set_sids, predict_set_lbls = hprotein.get_data(args.predict_folder, args.submission_folder, mode='test',\n",
    "                                                       filter_ids=[])\n",
    "print(predict_set_sids)\n",
    "predict_generator = hprotein.HproteinDataGenerator(args,\n",
    "                                                   args.predict_folder,\n",
    "                                                   predict_set_sids,\n",
    "                                                   predict_set_lbls,\n",
    "                                                   model_name=args.model_name)\n",
    "\n",
    "# generate predictions\n",
    "print('Starting prediction run...')\n",
    "\n",
    "# read in the list of samples in the correct order to submit\n",
    "submit = pd.read_csv('{}/sample_submission_short.csv'.format(args.submission_folder))\n",
    "\n",
    "# create an empty array to catch the predictions\n",
    "predictions = np.zeros((predict_set_sids.shape[0], 28))\n",
    "\n",
    "# get the predictions\n",
    "for i in range(len(predict_generator)):\n",
    "    if i % 10 == 0:\n",
    "        print('Predicting batch {} of {}'.format(i, len(predict_generator)))\n",
    "    images, labels = predict_generator[i]\n",
    "    score = final_model.predict(images)\n",
    "    predictions[i * predict_generator.batch_size : ((i * predict_generator.batch_size) + score.shape[0])] = score\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting labels for prediction 0 of 7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00cfafb0-bacb-11e8-b2b8-ac1f6b6435d0</td>\n",
       "      <td>0 27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00d2a4f8-bad6-11e8-b2b9-ac1f6b6435d0</td>\n",
       "      <td>0 25 27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000cce7e-bad4-11e8-b2b8-ac1f6b6435d0</td>\n",
       "      <td>7 27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0006faa6-bac7-11e8-b2b7-ac1f6b6435d0</td>\n",
       "      <td>0 5 25 27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0008baca-bad7-11e8-b2b9-ac1f6b6435d0</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>003170fa-bacd-11e8-b2b8-ac1f6b6435d0</td>\n",
       "      <td>23 25 27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0031820a-baca-11e8-b2b8-ac1f6b6435d0</td>\n",
       "      <td>2 25 27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Id  Predicted\n",
       "0  00cfafb0-bacb-11e8-b2b8-ac1f6b6435d0       0 27\n",
       "1  00d2a4f8-bad6-11e8-b2b9-ac1f6b6435d0    0 25 27\n",
       "2  000cce7e-bad4-11e8-b2b8-ac1f6b6435d0       7 27\n",
       "3  0006faa6-bac7-11e8-b2b7-ac1f6b6435d0  0 5 25 27\n",
       "4  0008baca-bad7-11e8-b2b9-ac1f6b6435d0         27\n",
       "5  003170fa-bacd-11e8-b2b8-ac1f6b6435d0   23 25 27\n",
       "6  0031820a-baca-11e8-b2b8-ac1f6b6435d0    2 25 27"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert the predictions into the submission file format\n",
    "prediction_str = []\n",
    "for row in range(submit.shape[0]):\n",
    "    if row % 200 == 0:\n",
    "        print('Converting labels for prediction {} of {}'.format(row, submit.shape[0]))\n",
    "    str_label = ''\n",
    "    for col in range(predictions.shape[1]):\n",
    "        if predictions[row, col] < max_thresholds_matrix[col]:\n",
    "            str_label += ''\n",
    "        else:\n",
    "            str_label += str(col) + ' '\n",
    "    prediction_str.append(str_label.strip())\n",
    "\n",
    "# add column to pandas dataframe for submission\n",
    "submit['Predicted'] = np.array(prediction_str)\n",
    "submit.head(7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
