{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/farrar/py3.6.5/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import cv2\n",
    "from tensorflow.python.lib.io import file_io\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, load_model, Model\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense, Input, Conv2D, MaxPooling2D, BatchNormalization, Concatenate, ReLU, LeakyReLU\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "TRAIN_PATH = '../stage1_train'\n",
    "TEST_PATH = '../stage1_test'\n",
    "LABEL_PATH = '../stage1_labels/train.csv'\n",
    "OUTPUT_PATH = '../stage1_submit'\n",
    "COLORS = ['red','green', 'blue', 'yellow']\n",
    "IMAGE_SIZE = 512\n",
    "BATCH_SIZE = 2\n",
    "SHAPE = (192, 192, 4)\n",
    "THRESHOLD = 0.05\n",
    "SEED = 42\n",
    "\n",
    "\n",
    "name_label_dict = {\n",
    "0:  'Nucleoplasm',\n",
    "1:  'Nuclear membrane',\n",
    "2:  'Nucleoli',   \n",
    "3:  'Nucleoli fibrillar center',\n",
    "4:  'Nuclear speckles',\n",
    "5:  'Nuclear bodies',\n",
    "6:  'Endoplasmic reticulum',   \n",
    "7:  'Golgi apparatus',\n",
    "8:  'Peroxisomes',\n",
    "9:  'Endosomes',\n",
    "10:  'Lysosomes',\n",
    "11:  'Intermediate filaments',\n",
    "12:  'Actin filaments',\n",
    "13:  'Focal adhesion sites',   \n",
    "14:  'Microtubules',\n",
    "15:  'Microtubule ends',  \n",
    "16:  'Cytokinetic bridge',   \n",
    "17:  'Mitotic spindle',\n",
    "18:  'Microtubule organizing center',  \n",
    "19:  'Centrosome',\n",
    "20:  'Lipid droplets',\n",
    "21:  'Plasma membrane',   \n",
    "22:  'Cell junctions', \n",
    "23:  'Mitochondria',\n",
    "24:  'Aggresome',\n",
    "25:  'Cytosol',\n",
    "26:  'Cytoplasmic bodies',   \n",
    "27:  'Rods & rings' }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fb4c1fac-bbaa-11e8-b2ba-ac1f6b6435d0', '002daad6-bbc9-11e8-b2bc-ac1f6b6435d0', 'fc84a97c-bbad-11e8-b2ba-ac1f6b6435d0', '001bcdd2-bbb2-11e8-b2ba-ac1f6b6435d0', '000c99ba-bba4-11e8-b2b9-ac1f6b6435d0', 'fea6e496-bbbb-11e8-b2ba-ac1f6b6435d0', '001838f8-bbca-11e8-b2bc-ac1f6b6435d0', 'ffeae6f0-bbc9-11e8-b2bc-ac1f6b6435d0', '0020af02-bbba-11e8-b2ba-ac1f6b6435d0', 'fffe0ffe-bbc0-11e8-b2bb-ac1f6b6435d0']\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------\n",
    "# get a list of unique specimen ids\n",
    "# -----------------------------------------\n",
    "def get_specimen_ids(path):\n",
    "\n",
    "    # get a list of all the images\n",
    "    file_list = file_io.list_directory(path)\n",
    "    \n",
    "    # truncate the file names to make a specimen id\n",
    "    specimen_ids = [f[:36] for f in file_list]\n",
    "    \n",
    "    # eliminate duplicates\n",
    "    specimen_ids = list(set(specimen_ids))\n",
    "    \n",
    "    return specimen_ids\n",
    "\n",
    "# unit test\n",
    "specimen_list = get_specimen_ids(TRAIN_PATH)\n",
    "print(specimen_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yo ../stage1_train\n",
      "../stage1_train/000c99ba-bba4-11e8-b2b9-ac1f6b6435d0_red.png\n"
     ]
    }
   ],
   "source": [
    "def get_image_fname(path, specimen_id, color, lo_res=True):\n",
    "\n",
    "    # construct filename\n",
    "    if lo_res:\n",
    "        fname = path + '/' + specimen_id + '_' + color + '.png'\n",
    "    else:\n",
    "        fname = path + '/' + specimen_id + '_' + color + '.tif'\n",
    "        \n",
    "    return fname\n",
    "\n",
    "# unit test\n",
    "s = '000c99ba-bba4-11e8-b2b9-ac1f6b6435d0'\n",
    "f = get_image_fname(TRAIN_PATH, s, 'red')\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00070df0-bbc3-11e8-b2bc-ac1f6b6435d0</td>\n",
       "      <td>16 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000a6c98-bb9b-11e8-b2b9-ac1f6b6435d0</td>\n",
       "      <td>7 1 2 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000a9596-bbc4-11e8-b2bc-ac1f6b6435d0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000c99ba-bba4-11e8-b2b9-ac1f6b6435d0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001838f8-bbca-11e8-b2bc-ac1f6b6435d0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>001bcdd2-bbb2-11e8-b2ba-ac1f6b6435d0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0020af02-bbba-11e8-b2ba-ac1f6b6435d0</td>\n",
       "      <td>25 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>002679c2-bbb6-11e8-b2ba-ac1f6b6435d0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>00285ce4-bba0-11e8-b2b9-ac1f6b6435d0</td>\n",
       "      <td>2 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>002daad6-bbc9-11e8-b2bc-ac1f6b6435d0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Id   Target\n",
       "0  00070df0-bbc3-11e8-b2bc-ac1f6b6435d0     16 0\n",
       "1  000a6c98-bb9b-11e8-b2b9-ac1f6b6435d0  7 1 2 0\n",
       "2  000a9596-bbc4-11e8-b2bc-ac1f6b6435d0        5\n",
       "3  000c99ba-bba4-11e8-b2b9-ac1f6b6435d0        1\n",
       "4  001838f8-bbca-11e8-b2bc-ac1f6b6435d0       18\n",
       "5  001bcdd2-bbb2-11e8-b2ba-ac1f6b6435d0        0\n",
       "6  0020af02-bbba-11e8-b2ba-ac1f6b6435d0     25 2\n",
       "7  002679c2-bbb6-11e8-b2ba-ac1f6b6435d0        0\n",
       "8  00285ce4-bba0-11e8-b2b9-ac1f6b6435d0      2 0\n",
       "9  002daad6-bbc9-11e8-b2bc-ac1f6b6435d0        7"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels = pd.read_csv(LABEL_PATH)\n",
    "train_labels.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    [7, 1, 2, 0]\n",
      "Name: Target, dtype: object\n"
     ]
    }
   ],
   "source": [
    "selection_list = ['000a6c98-bb9b-11e8-b2b9-ac1f6b6435d0', s, '001838f8-bbca-11e8-b2bc-ac1f6b6435d0']\n",
    "subset = train_labels.loc[train_labels['Id'].isin(selection_list)]\n",
    "subset.head()\n",
    "split_labels = (subset.loc[subset['Id'] == '000a6c98-bb9b-11e8-b2b9-ac1f6b6435d0'])['Target'].str.split(' ')\n",
    "print (split_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------\n",
    "# Keras style run time data generator\n",
    "# ---------------------------------------\n",
    "class HproteinDataGenerator(keras.utils.Sequence):\n",
    "    \n",
    "    # ---------------------------------------------\n",
    "    # Required function to initialize the class\n",
    "    # ---------------------------------------------\n",
    "    def __init__(self, \n",
    "                 path,\n",
    "                 specimen_ids, \n",
    "                 labels, \n",
    "                 batch_size=BATCH_SIZE, \n",
    "                 shape=SHAPE, \n",
    "                 shuffle=False, \n",
    "                 use_cache=False, \n",
    "                 augment=False):\n",
    "       \n",
    "        self.path = path                       # path where data generator will find data\n",
    "        self.specimen_ids = specimen_ids       # list of features\n",
    "        self.labels = labels                   # list of labels\n",
    "        self.batch_size = batch_size           # batch size\n",
    "        self.shape = shape                     # shape of features\n",
    "        self.shuffle = shuffle                 # boolean for shuffle\n",
    "        self.use_cache = use_cache             # boolean for use of cache\n",
    "        self.augment = augment                 # boolean for image augmentation\n",
    "        \n",
    "    # -------------------------------------------------------\n",
    "    # Required function to determine the number of batches\n",
    "    # -------------------------------------------------------\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.specimen_ids) / float(self.batch_size)))\n",
    "    \n",
    "    # -------------------------------------------------------\n",
    "    # Required function to get a batch\n",
    "    # -------------------------------------------------------\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        # get the list of specimen ids for this batch\n",
    "        specimen_ids = self.specimen_ids[self.batch_size*index:self.batch_size*(index + 1)]\n",
    "                \n",
    "        # create a zeroed out numpy array to load the batch into\n",
    "        feature_batch = np.zeros((len(specimen_ids), self.shape[0], self.shape[1], self.shape[2]))\n",
    "        \n",
    "        # load a batch of labels\n",
    "        label_batch = self.labels[self.batch_size*index:self.batch_size*(index + 1)]\n",
    "        \n",
    "        # load a batch of images\n",
    "        if self.use_cache:\n",
    "            print(\"Error: use_cache not implemented!\")\n",
    "        else:\n",
    "            for i, specimen_id in enumerate(specimen_ids):\n",
    "                feature_batch[i] = self.get_stacked_image(specimen_id)\n",
    "            \n",
    "        # augment images if desired\n",
    "        if self.augment:\n",
    "            print(\"Error: Image augmentation not implemented!\")\n",
    "            \n",
    "        return feature_batch, label_batch\n",
    "            \n",
    "            \n",
    "    # -----------------------------------------\n",
    "    # get a single image\n",
    "    # -----------------------------------------\n",
    "    def get_single_image(self, specimen_id, color, lo_res=True):\n",
    "\n",
    "        # get image file name\n",
    "        fname = get_image_fname(self.path, specimen_id, color, lo_res)\n",
    "        \n",
    "        # read image as a 1-channel image\n",
    "        image = cv2.imread(fname, cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        # resize to the model image size\n",
    "        image = cv2.resize(image, (self.shape[0], self.shape[1]))\n",
    "\n",
    "        return image\n",
    "    \n",
    "            \n",
    "    # -----------------------------------------\n",
    "    # get a stacked (4-channel) image\n",
    "    # -----------------------------------------\n",
    "    def get_stacked_image(self, specimen_id, lo_res=True):\n",
    "\n",
    "        # create a numpy array to place the 1-channel images into\n",
    "        image = np.zeros((self.shape[0], self.shape[1], 4), dtype=np.uint8)\n",
    "\n",
    "        for n, color in enumerate(COLORS):\n",
    "\n",
    "            # get a single image\n",
    "            i = self.get_single_image(specimen_id, color, lo_res)\n",
    "\n",
    "            # store it a channel\n",
    "            image[:, :, n] = i\n",
    "\n",
    "        return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specimen Id: fb4c1fac-bbaa-11e8-b2ba-ac1f6b6435d0 : Labels: [1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Specimen Id: 002daad6-bbc9-11e8-b2bc-ac1f6b6435d0 : Labels: [0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Specimen Id: fc84a97c-bbad-11e8-b2ba-ac1f6b6435d0 : Labels: [1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Specimen Id: 001bcdd2-bbb2-11e8-b2ba-ac1f6b6435d0 : Labels: [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Specimen Id: 000c99ba-bba4-11e8-b2b9-ac1f6b6435d0 : Labels: [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Specimen Id: fea6e496-bbbb-11e8-b2ba-ac1f6b6435d0 : Labels: [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Specimen Id: 001838f8-bbca-11e8-b2bc-ac1f6b6435d0 : Labels: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "Specimen Id: ffeae6f0-bbc9-11e8-b2bc-ac1f6b6435d0 : Labels: [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      "Specimen Id: 0020af02-bbba-11e8-b2ba-ac1f6b6435d0 : Labels: [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      "Specimen Id: fffe0ffe-bbc0-11e8-b2bb-ac1f6b6435d0 : Labels: [1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------------------\n",
    "# get the available specimen ids and corresponding labels\n",
    "# -----------------------------------------------------------\n",
    "def get_train_data(train_path, label_path):\n",
    "    \n",
    "    # get the list of specimen ids\n",
    "    specimen_ids = get_specimen_ids(train_path)\n",
    "    \n",
    "    # get the labels for all specimen_ids\n",
    "    label_data = pd.read_csv(label_path)\n",
    "    \n",
    "    # get the subset of labels that match the specimen images that are on TRAIN_PATH\n",
    "    labels_subset = label_data.loc[label_data['Id'].isin(specimen_ids)]\n",
    "    \n",
    "    #\n",
    "    # convert labels to trainer format\n",
    "    #\n",
    "    \n",
    "    # set up the list that will contain the list of encoded labels for each specimen id\n",
    "    labels = []\n",
    "    \n",
    "    # loop through each specimen_id\n",
    "    for specimen_id in specimen_ids:\n",
    "        \n",
    "        # split the space separated multi-label into a list of individual labels\n",
    "        split_labels = (labels_subset.loc[labels_subset['Id'] == specimen_id])['Target'].str.split(' ')\n",
    "\n",
    "        # set up a numpy array to receive the encoded label\n",
    "        l = np.zeros(28, dtype=np.uint8)\n",
    "\n",
    "        # turn on the positive columns in the labels array\n",
    "        for label in split_labels:\n",
    "            l[np.uint8(label)] = 1\n",
    "        \n",
    "        labels.append(l)\n",
    "        \n",
    "    return np.array(specimen_ids), np.array(labels)\n",
    "\n",
    "# unit test \n",
    "specimen_ids, labels = get_train_data(TRAIN_PATH, LABEL_PATH)\n",
    "for sid, l in zip(specimen_ids, labels):\n",
    "    print('Specimen Id: {} : Labels: {}'.format(sid, l))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specimen Id: 0006faa6-bac7-11e8-b2b7-ac1f6b6435d0 : Labels: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Specimen Id: 0008baca-bad7-11e8-b2b9-ac1f6b6435d0 : Labels: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Specimen Id: 00d2a4f8-bad6-11e8-b2b9-ac1f6b6435d0 : Labels: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Specimen Id: 003170fa-bacd-11e8-b2b8-ac1f6b6435d0 : Labels: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Specimen Id: 0031820a-baca-11e8-b2b8-ac1f6b6435d0 : Labels: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Specimen Id: 00cfafb0-bacb-11e8-b2b8-ac1f6b6435d0 : Labels: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Specimen Id: 000cce7e-bad4-11e8-b2b8-ac1f6b6435d0 : Labels: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------------------\n",
    "# get the specimen ids to predict\n",
    "# -----------------------------------------------------------\n",
    "def get_predict_data(test_path, output_path):\n",
    "    \n",
    "    # get the list of specimen ids for which there are images\n",
    "    specimen_ids = get_specimen_ids(test_path)\n",
    "    \n",
    "    # get the list of submission specimen ids required\n",
    "    submit_data = pd.read_csv(output_path + '/sample_submission.csv')\n",
    "    \n",
    "    # get the subset of labels that match the specimen images that are on TEST_PATH\n",
    "    submit_subset = submit_data.loc[submit_data['Id'].isin(specimen_ids)]\n",
    "    \n",
    "    # set up the list that will contain the list of encoded labels for each specimen id\n",
    "    predicted_labels = np.zeros((len(specimen_ids), 28), dtype=np.uint8)\n",
    "    \n",
    "    return np.array(specimen_ids), predicted_labels\n",
    "\n",
    "# unit test \n",
    "specimen_ids, labels = get_predict_data(TEST_PATH, OUTPUT_PATH)\n",
    "for sid, l in zip(specimen_ids, labels):\n",
    "    print('Specimen Id: {} : Labels: {}'.format(sid, l))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9473683\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------\n",
    "# calculate the f1 statistic\n",
    "# --------------------------------\n",
    "def f1(y_true, y_pred):\n",
    "    \n",
    "    #y_pred = K.round(y_pred)\n",
    "    y_pred = K.cast(K.greater(K.clip(y_pred, 0, 1), THRESHOLD), K.floatx())\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    \n",
    "    return K.mean(f1)\n",
    "\n",
    "# unit test\n",
    "y_true = K.variable(np.ones(10, np.uint8))\n",
    "y_pred = np.ones(10, np.uint8)\n",
    "y_pred[0] = 0\n",
    "y_pred = K.variable(y_pred)\n",
    "\n",
    "ftest = f1(y_true, y_pred)\n",
    "#ftest = tf.constant(5)\n",
    "\n",
    "init_op = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init_op)\n",
    "print (sess.run(ftest))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.052631676\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------\n",
    "# calculate the f1 loss\n",
    "# --------------------------------\n",
    "\n",
    "def f1_loss(y_true, y_pred):\n",
    "\n",
    "    f = f1(y_true, y_pred)\n",
    "    \n",
    "    return 1 - K.mean(f)\n",
    "\n",
    "# unit test\n",
    "y_true = K.variable(np.ones(10, np.uint8))\n",
    "y_pred = np.ones(10, np.uint8)\n",
    "y_pred[0] = 0\n",
    "y_pred = K.variable(y_pred)\n",
    "\n",
    "ftest = f1_loss(y_true, y_pred)\n",
    "#ftest = tf.constant(5)\n",
    "\n",
    "init_op = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init_op)\n",
    "print (sess.run(ftest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 192, 192, 4)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 192, 192, 4)  16          input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 190, 190, 8)  296         batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_1 (ReLU)                  (None, 190, 190, 8)  0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 190, 190, 8)  32          re_lu_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 188, 188, 8)  584         batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_2 (ReLU)                  (None, 188, 188, 8)  0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 188, 188, 8)  32          re_lu_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 186, 186, 16) 1168        batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_3 (ReLU)                  (None, 186, 186, 16) 0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 186, 186, 16) 64          re_lu_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 93, 93, 16)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 93, 93, 16)   0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 93, 93, 16)   2320        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 93, 93, 16)   6416        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 93, 93, 16)   12560       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 93, 93, 16)   272         dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_4 (ReLU)                  (None, 93, 93, 16)   0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_5 (ReLU)                  (None, 93, 93, 16)   0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_6 (ReLU)                  (None, 93, 93, 16)   0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_7 (ReLU)                  (None, 93, 93, 16)   0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 93, 93, 64)   0           re_lu_4[0][0]                    \n",
      "                                                                 re_lu_5[0][0]                    \n",
      "                                                                 re_lu_6[0][0]                    \n",
      "                                                                 re_lu_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 93, 93, 64)   256         concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 46, 46, 64)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 46, 46, 64)   0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 44, 44, 32)   18464       dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_8 (ReLU)                  (None, 44, 44, 32)   0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 44, 44, 32)   128         re_lu_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 22, 22, 32)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 22, 22, 32)   0           max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 20, 20, 64)   18496       dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_9 (ReLU)                  (None, 20, 20, 64)   0           conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 20, 20, 64)   256         re_lu_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 10, 10, 64)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 10, 10, 64)   0           max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 8, 8, 128)    73856       dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_10 (ReLU)                 (None, 8, 8, 128)    0           conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 8, 8, 128)    512         re_lu_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 4, 4, 128)    0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 4, 4, 128)    0           max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 2048)         0           dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 2048)         0           flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 28)           57372       dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_11 (ReLU)                 (None, 28)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 28)           112         re_lu_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 28)           0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 28)           812         dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 28)           0           dense_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 194,024\n",
      "Trainable params: 193,320\n",
      "Non-trainable params: 704\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------\n",
    "# create the model\n",
    "# ------------------------------\n",
    "def create_model(input_shape):\n",
    "\n",
    "    dropRate = 0.25\n",
    "    \n",
    "    init = Input(input_shape)\n",
    "    x = BatchNormalization(axis=-1)(init)\n",
    "    x = Conv2D(8, (3, 3))(x)\n",
    "    x = ReLU()(x)\n",
    "    x = BatchNormalization(axis=-1)(x)\n",
    "    x = Conv2D(8, (3, 3))(x)\n",
    "    x = ReLU()(x)\n",
    "    x = BatchNormalization(axis=-1)(x)\n",
    "    x = Conv2D(16, (3, 3))(x)\n",
    "    x = ReLU()(x)\n",
    "    x = BatchNormalization(axis=-1)(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Dropout(dropRate)(x)\n",
    "    c1 = Conv2D(16, (3, 3), padding='same')(x)\n",
    "    c1 = ReLU()(c1)\n",
    "    c2 = Conv2D(16, (5, 5), padding='same')(x)\n",
    "    c2 = ReLU()(c2)\n",
    "    c3 = Conv2D(16, (7, 7), padding='same')(x)\n",
    "    c3 = ReLU()(c3)\n",
    "    c4 = Conv2D(16, (1, 1), padding='same')(x)\n",
    "    c4 = ReLU()(c4)\n",
    "    x = Concatenate()([c1, c2, c3, c4])\n",
    "    x = BatchNormalization(axis=-1)(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Dropout(dropRate)(x)\n",
    "    x = Conv2D(32, (3, 3))(x)\n",
    "    x = ReLU()(x)\n",
    "    x = BatchNormalization(axis=-1)(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Dropout(dropRate)(x)\n",
    "    x = Conv2D(64, (3, 3))(x)\n",
    "    x = ReLU()(x)\n",
    "    x = BatchNormalization(axis=-1)(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Dropout(dropRate)(x)\n",
    "    x = Conv2D(128, (3, 3))(x)\n",
    "    x = ReLU()(x)\n",
    "    x = BatchNormalization(axis=-1)(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Dropout(dropRate)(x)\n",
    "    #x = Conv2D(256, (1, 1), activation='relu')(x)\n",
    "    #x = BatchNormalization(axis=-1)(x)\n",
    "    #x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    #x = Dropout(0.25)(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(28)(x)\n",
    "    x = ReLU()(x)\n",
    "    x = BatchNormalization(axis=-1)(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    x = Dense(28)(x)\n",
    "    x = Activation('sigmoid')(x)\n",
    "    \n",
    "    model = Model(init, x)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# unit test\n",
    "model = create_model(SHAPE)\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer=Adam(1e-03),\n",
    "    metrics=['acc',f1])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7,)\n",
      "(3,)\n",
      "4\n",
      "2\n",
      "['0020af02-bbba-11e8-b2ba-ac1f6b6435d0'\n",
      " '002daad6-bbc9-11e8-b2bc-ac1f6b6435d0'\n",
      " 'fea6e496-bbbb-11e8-b2ba-ac1f6b6435d0'] [[0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# get data\n",
    "def get_data(test_size=0.1):\n",
    "    \n",
    "    specimen_ids, labels = get_train_data(TRAIN_PATH, LABEL_PATH)\n",
    "    train_set_sids, val_set_sids, train_set_lbls, val_set_lbls = train_test_split(specimen_ids, labels, test_size=test_size, random_state=SEED)\n",
    "    \n",
    "    return train_set_sids, val_set_sids, train_set_lbls, val_set_lbls\n",
    "\n",
    "# unit test\n",
    "train_set_sids, val_set_sids, train_set_lbls, val_set_lbls = get_data(test_size=0.3)\n",
    "print (train_set_sids.shape)\n",
    "print (val_set_sids.shape)\n",
    "\n",
    "# create data generators\n",
    "tg = HproteinDataGenerator(TRAIN_PATH, train_set_sids, train_set_lbls)\n",
    "vg = HproteinDataGenerator(TRAIN_PATH, val_set_sids, val_set_lbls)\n",
    "print(len(tg))\n",
    "print(len(vg))\n",
    "print (val_set_sids, val_set_lbls)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint('./base.model', monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='min', period=1)\n",
    "reduceLROnPlato = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1, mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "3/4 [=====================>........] - ETA: 1s - loss: 0.7556 - acc: 0.6071 - f1: 0.0635yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "4/4 [==============================] - 7s 2s/step - loss: 0.7871 - acc: 0.5597 - f1: 0.0694 - val_loss: 5.3617 - val_acc: 0.4167 - val_f1: 0.0278\n",
      "\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 5.36174, saving model to ./base.model\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "Epoch 2/5\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.7345 - acc: 0.5357 - f1: 0.0794yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "4/4 [==============================] - 4s 889ms/step - loss: 0.7238 - acc: 0.6255 - f1: 0.0694 - val_loss: 1.1502 - val_acc: 0.5119 - val_f1: 0.0595\n",
      "\n",
      "Epoch 00002: val_loss improved from 5.36174 to 1.15023, saving model to ./base.model\n",
      "Epoch 3/5\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.7065 - acc: 0.6726 - f1: 0.0754yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "4/4 [==============================] - 3s 848ms/step - loss: 0.7038 - acc: 0.6301 - f1: 0.0694 - val_loss: 1.2105 - val_acc: 0.4405 - val_f1: 0.0595\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.15023\n",
      "Epoch 4/5\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.7420 - acc: 0.6071 - f1: 0.0556yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "4/4 [==============================] - 3s 793ms/step - loss: 0.7425 - acc: 0.5724 - f1: 0.0694 - val_loss: 0.9806 - val_acc: 0.4881 - val_f1: 0.0595\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.15023 to 0.98062, saving model to ./base.model\n",
      "Epoch 5/5\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.7184 - acc: 0.6429 - f1: 0.0556yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "4/4 [==============================] - 3s 831ms/step - loss: 0.7158 - acc: 0.6128 - f1: 0.0694 - val_loss: 0.9025 - val_acc: 0.5000 - val_f1: 0.0595\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.98062 to 0.90245, saving model to ./base.model\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "\n",
    "use_multiprocessing = False # DO NOT COMBINE MULTIPROCESSING WITH CACHE! \n",
    "workers = 1 # DO NOT COMBINE MULTIPROCESSING WITH CACHE! \n",
    "\n",
    "hist = model.fit_generator(\n",
    "    tg,\n",
    "    steps_per_epoch=len(tg),\n",
    "    validation_data=vg,\n",
    "    validation_steps=8,\n",
    "    epochs=epochs,\n",
    "    use_multiprocessing=use_multiprocessing,\n",
    "    workers=workers,\n",
    "    verbose=1,\n",
    "    callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x13171ba58>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(15,5))\n",
    "ax[0].set_title('loss')\n",
    "ax[0].plot(hist.epoch, hist.history[\"loss\"], label=\"Train loss\")\n",
    "ax[0].plot(hist.epoch, hist.history[\"val_loss\"], label=\"Validation loss\")\n",
    "ax[1].set_title('acc')\n",
    "ax[1].plot(hist.epoch, hist.history[\"f1\"], label=\"Train F1\")\n",
    "ax[1].plot(hist.epoch, hist.history[\"val_f1\"], label=\"Validation F1\")\n",
    "ax[0].legend()\n",
    "ax[1].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = load_model('./base.model', custom_objects={'f1': f1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "yo ../stage1_train\n",
      "(3, 28)\n",
      "(3, 28)\n",
      "[[0.9013449  0.29278445 0.6463421  0.5312804  0.19979945 0.65227258\n",
      "  0.16426794 0.67117369 0.35199678 0.70725989 0.59207106 0.44577381\n",
      "  0.39068687 0.7032938  0.71293789 0.60650408 0.78125757 0.19327042\n",
      "  0.15799332 0.52583569 0.61240923 0.47508913 0.69142699 0.33284459\n",
      "  0.82450622 0.56315655 0.48634335 0.80976468]\n",
      " [0.88479847 0.27402505 0.91764092 0.6901626  0.18048802 0.39401391\n",
      "  0.25546139 0.82570851 0.09970398 0.79809171 0.43345132 0.74333984\n",
      "  0.148056   0.5491485  0.6116268  0.46854535 0.92856336 0.33312941\n",
      "  0.2335531  0.37574455 0.57377195 0.10157727 0.57826841 0.20377694\n",
      "  0.66850537 0.83767366 0.31163183 0.69525474]\n",
      " [0.93544245 0.3944914  0.29177165 0.80268854 0.09402827 0.26859757\n",
      "  0.19035368 0.78584671 0.43160617 0.54880315 0.09983832 0.74876708\n",
      "  0.36073259 0.67163855 0.81872243 0.14838105 0.95326239 0.17104988\n",
      "  0.1253307  0.22549552 0.72035891 0.44139484 0.96734077 0.22453845\n",
      "  0.740991   0.57867217 0.33178902 0.86970586]]\n"
     ]
    }
   ],
   "source": [
    "val_predictions = np.empty((0, 28))\n",
    "val_labels = np.empty((0, 28))\n",
    "for i in range(len(vg)):\n",
    "    image, label = vg[i]\n",
    "    scores = final_model.predict(image)\n",
    "    #print('scores -> {}'.format(scores))\n",
    "    #print('label  -> {}'.format(label))\n",
    "    val_predictions = np.append(val_predictions, scores, axis=0)\n",
    "    val_labels = np.append(val_labels, label, axis=0)\n",
    "print(val_predictions.shape)\n",
    "print(val_labels.shape)\n",
    "print(val_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/farrar/py3.6.5/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/Users/farrar/py3.6.5/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 28)\n",
      "[[0.  0.  0.5 ... 0.5 0.  0. ]\n",
      " [0.  0.  0.5 ... 0.5 0.  0. ]\n",
      " [0.  0.  0.5 ... 0.5 0.  0. ]\n",
      " ...\n",
      " [0.  0.  0.  ... 0.  0.  0. ]\n",
      " [0.  0.  0.  ... 0.  0.  0. ]\n",
      " [0.  0.  0.  ... 0.  0.  0. ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "rng = np.arange(0, 1, 0.001)\n",
    "fscores = np.zeros((rng.shape[0], 28))\n",
    "for j,k in enumerate(rng):\n",
    "    for i in range(28):\n",
    "        p = np.array(val_predictions[:,i]>k, dtype=np.int8)\n",
    "        #print('p -> {}'.format(p))\n",
    "        #print('v -> {}'.format(val_predictions[:,i]))\n",
    "        #print('l -> {}'.format(val_labels[:,i]))\n",
    "        score = f1_score(val_labels[:,i], p, average='binary')\n",
    "        #print(score)\n",
    "        fscores[j,i] = score\n",
    "        \n",
    "        \n",
    "print (fscores.shape)\n",
    "print (fscores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual F1-scores for each class:\n",
      "[0.         0.         0.66666667 0.         0.         0.\n",
      " 0.         1.         0.         0.         0.         0.\n",
      " 0.66666667 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.5        0.         0.        ]\n",
      "Macro F1-score CV = 0.10119047619047618\n"
     ]
    }
   ],
   "source": [
    "print('Individual F1-scores for each class:')\n",
    "print(np.max(fscores, axis=0))\n",
    "print('Macro F1-score CV =', np.mean(np.max(fscores, axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability threshold maximizing CV F1-score for each class:\n",
      "[0.    0.    0.292 0.    0.    0.    0.    0.786 0.    0.    0.    0.\n",
      " 0.149 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.   ]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(rng, fscores)\n",
    "T = np.empty(28)\n",
    "for i in range(28):\n",
    "    T[i] = rng[np.where(fscores[:,i] == np.max(fscores[:,i]))[0][0]]\n",
    "print('Probability threshold maximizing CV F1-score for each class:')\n",
    "print(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'labels'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-ae6b0d186297>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpredict_set_sids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict_set_lbls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_predict_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTEST_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOUTPUT_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHproteinDataGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict_set_sids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict_set_lbls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpredict_set_sids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict_set_lbls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'labels'"
     ]
    }
   ],
   "source": [
    "predict_set_sids, predict_set_lbls = get_predict_data(TEST_PATH, OUTPUT_PATH)\n",
    "pg = HproteinDataGenerator(TEST_PATH, predict_set_sids, predict_set_lbls)\n",
    "\n",
    "print(len(pg))\n",
    "print (predict_set_sids, predict_set_lbls)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(pg)):\n",
    "    images, labels = pg[i]\n",
    "    score = final_model.predict(images)\n",
    "    predictions[i*BATCH_SIZE:i*BATCH_SIZE+score.shape[0]] = score\n",
    "    \n",
    "print (predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
